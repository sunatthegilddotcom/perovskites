{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_loading_example",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+pu5EqYtThFwkZmIkHqKp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1d22432c0794170980f9d2d8e8104a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_638aab806ecf4583bf5df92486a77a30",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_60be1e83240848e8ab22988c110c5f43",
              "IPY_MODEL_cfb4614ddd134dedb3e5630538b9e28e"
            ]
          }
        },
        "638aab806ecf4583bf5df92486a77a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60be1e83240848e8ab22988c110c5f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c596b8eb4009401791dbcd8db76dd84d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_199e53964ae34453a6d2a25dcc27e682"
          }
        },
        "cfb4614ddd134dedb3e5630538b9e28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b23a857987594103b66aac2885838d61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [13:16&lt;00:00,  1.26epoch/s, loss=18.9, val_loss=484]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_597cddb63967459bbd6e473108f5fe47"
          }
        },
        "c596b8eb4009401791dbcd8db76dd84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "199e53964ae34453a6d2a25dcc27e682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b23a857987594103b66aac2885838d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "597cddb63967459bbd6e473108f5fe47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afarley9/perovskites/blob/main/examples/data_loading_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R0o46GwOkeY"
      },
      "source": [
        "### This notebook is an example of how our data is being loaded from the Google Shared Drive by the team members.\r\n",
        "## **Note that the training data is available only to the members to the team. So, only the team members can access the master index csv file.**\r\n",
        "\r\n",
        "This is how Google colab's `mount` is being used to read data directly from the drive without downloading or uploading. By directly routing data to the Colab's virtual machine, we will be able stream line it directly into the neural network being built by other team folks.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXgsvUPoJQxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81933c2c-d8a6-41e0-d7b2-4b68b3225ee1"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import sys, pickle\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers, Sequential\r\n",
        "from tqdm.keras import TqdmCallback\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# Mount the drive and clone the github repo\r\n",
        "drive.mount('/content/drive/')\r\n",
        "!git clone https://github.com/afarley9/perovskites.git\r\n",
        "\r\n",
        "# Import modules from the github repo\r\n",
        "sys.path.append(\"/content/perovskites/perovskites\")\r\n",
        "import utils.image_processing as impr\r\n",
        "import utils.image_loader as loader\r\n",
        "\r\n",
        "MODEL_LOG_FILE = \"drive/Shareddrives/Perovskites_DIRECT/tensorboard_logs\"\r\n",
        "MODEL_INFO = loader.MODEL_INFO\r\n",
        "final_img_size = MODEL_INFO['target_image_size_pix']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "fatal: destination path 'perovskites' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1uW40L03H1e"
      },
      "source": [
        "Import the packages from the cloned git repository where all the python codes are present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRVF6czZ3Eao"
      },
      "source": [
        "dataset = loader.PLDataLoader()\r\n",
        "X_train, X_test, y_train, y_test = dataset.train_test_split(test_size=0.2,\r\n",
        "                                                            random_state=42,\r\n",
        "                                                            shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imz_GmarPQW7"
      },
      "source": [
        "All the paths to the relevant images and the corresponding experimental metadata are stored in a master csv file which lists details of **1,257 individual degradation experiments**. So this study is going to be done on a well-documented and experimentally collected dataset. But, the challenge is that since the data is experimentally collected and is prone to human-induced and other irreducible noise, it is required to undergo an extensive data-cleaning process to get reliable results. As used above, the `PLDataLoader()` can be used to load the data and also make the test-train splits. ***Note that the dataset is currently available only to the team members due to confidentiality of the data as most of it is unpublished***.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oivGnDfXgDQP"
      },
      "source": [
        "This is the part where we are creating a scope for TPU runtime. We create the model inside the `tpu_strategy.scope` after connecting to a **Google Cloud TPU**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpvUOuC3j27n",
        "outputId": "5dc86fc9-6fc2-43cc-8ded-aa896e5d64c3"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Running on TPU  ['10.7.171.162:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.7.171.162:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.7.171.162:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_Gcqf_CgbIY"
      },
      "source": [
        "Now, create the sequential NN layers using `tf.keras.Sequential()` and train the CNN model using a TPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e1d22432c0794170980f9d2d8e8104a7",
            "638aab806ecf4583bf5df92486a77a30",
            "60be1e83240848e8ab22988c110c5f43",
            "cfb4614ddd134dedb3e5630538b9e28e",
            "c596b8eb4009401791dbcd8db76dd84d",
            "199e53964ae34453a6d2a25dcc27e682",
            "b23a857987594103b66aac2885838d61",
            "597cddb63967459bbd6e473108f5fe47"
          ]
        },
        "id": "gJtQmfHcjqND",
        "outputId": "58d297e8-278f-432a-84c7-1f784f0969fd"
      },
      "source": [
        "def create_model():\r\n",
        "    model = Sequential([\r\n",
        "                        layers.Conv2D(32, 3, padding='valid', use_bias=True,\r\n",
        "                                    input_shape=(final_img_size,\r\n",
        "                                                     final_img_size, 1),\r\n",
        "                                    kernel_initializer='normal',\r\n",
        "                                    activation='relu'),\r\n",
        "                        layers.MaxPooling2D(),\r\n",
        "                        layers.Conv2D(32, 3, padding='valid', use_bias=True,\r\n",
        "                                      kernel_initializer='normal', activation='relu'),\r\n",
        "                        layers.MaxPooling2D(),\r\n",
        "                        layers.Conv2D(64, 3, padding='valid', use_bias=True,\r\n",
        "                                      kernel_initializer='normal', activation='relu'),\r\n",
        "                        layers.MaxPooling2D(),\r\n",
        "                        layers.Flatten(),\r\n",
        "                        layers.Dense(128, activation='relu',\r\n",
        "                                    kernel_initializer='normal',\r\n",
        "                                    use_bias=True, ),\r\n",
        "                        layers.Dense(1, activation='linear',\r\n",
        "                                    use_bias=True, )\r\n",
        "                        ])\r\n",
        "\r\n",
        "    model.compile(loss='mean_absolute_error', optimizer='nadam')\r\n",
        "    return model\r\n",
        "\r\n",
        "# Define callbacks\r\n",
        "callbacks = [\r\n",
        "    #tf.keras.callbacks.TensorBoard(log_dir=MODEL_LOG_FILE),\r\n",
        "    TqdmCallback(verbose=0),\r\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1d22432c0794170980f9d2d8e8104a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bycAAN1EjiX7",
        "outputId": "054de2be-62b5-4208-ac8c-ab8bdbb7da18"
      },
      "source": [
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\r\n",
        "    model = create_model()\r\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 61,089\n",
            "Trainable params: 61,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsNZW1W2dTGi",
        "outputId": "5911c469-4980-48ef-ddd1-55ddc01b8391"
      },
      "source": [
        "from keras.models import model_from_json\r\n",
        "from keras.models import load_model\r\n",
        "\r\n",
        "# Training\r\n",
        "epochs=1000\r\n",
        "batch_size=25\r\n",
        "history = model.fit(\r\n",
        "    x=X_train,\r\n",
        "    y=y_train,\r\n",
        "    epochs=epochs,\r\n",
        "    batch_size=batch_size,\r\n",
        "    verbose=2,\r\n",
        "    validation_data=(X_test, y_test),\r\n",
        "    callbacks=callbacks)\r\n",
        "\r\n",
        "# serialize model to JSON\r\n",
        "#  the keras model which is trained is defined as 'model' in this example\r\n",
        "model_json = model.to_json()\r\n",
        "\r\n",
        "with open(\"drive/Shareddrives/Perovskites_DIRECT/model_num.json\", \"w\") as json_file:\r\n",
        "    json_file.write(model_json)\r\n",
        "\r\n",
        "# serialize weights to HDF5\r\n",
        "model.save_weights(\"drive/Shareddrives/Perovskites_DIRECT/model_num.h5\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "40/40 - 10s - loss: 355.4131 - val_loss: 443.4276\n",
            "Epoch 2/1000\n",
            "40/40 - 1s - loss: 344.2941 - val_loss: 453.0222\n",
            "Epoch 3/1000\n",
            "40/40 - 1s - loss: 343.6145 - val_loss: 441.0719\n",
            "Epoch 4/1000\n",
            "40/40 - 1s - loss: 347.1334 - val_loss: 437.3837\n",
            "Epoch 5/1000\n",
            "40/40 - 1s - loss: 343.6576 - val_loss: 440.5928\n",
            "Epoch 6/1000\n",
            "40/40 - 1s - loss: 343.0498 - val_loss: 447.8474\n",
            "Epoch 7/1000\n",
            "40/40 - 1s - loss: 341.7868 - val_loss: 442.9713\n",
            "Epoch 8/1000\n",
            "40/40 - 1s - loss: 343.3658 - val_loss: 436.9901\n",
            "Epoch 9/1000\n",
            "40/40 - 1s - loss: 343.9438 - val_loss: 436.4025\n",
            "Epoch 10/1000\n",
            "40/40 - 1s - loss: 340.8170 - val_loss: 436.2097\n",
            "Epoch 11/1000\n",
            "40/40 - 1s - loss: 341.8834 - val_loss: 437.2287\n",
            "Epoch 12/1000\n",
            "40/40 - 1s - loss: 340.8029 - val_loss: 435.2328\n",
            "Epoch 13/1000\n",
            "40/40 - 1s - loss: 339.3422 - val_loss: 448.0275\n",
            "Epoch 14/1000\n",
            "40/40 - 1s - loss: 348.0331 - val_loss: 436.1222\n",
            "Epoch 15/1000\n",
            "40/40 - 1s - loss: 338.8111 - val_loss: 438.3716\n",
            "Epoch 16/1000\n",
            "40/40 - 1s - loss: 338.8953 - val_loss: 436.5626\n",
            "Epoch 17/1000\n",
            "40/40 - 1s - loss: 338.3122 - val_loss: 433.7218\n",
            "Epoch 18/1000\n",
            "40/40 - 1s - loss: 336.9398 - val_loss: 435.0948\n",
            "Epoch 19/1000\n",
            "40/40 - 1s - loss: 335.0919 - val_loss: 434.1781\n",
            "Epoch 20/1000\n",
            "40/40 - 1s - loss: 335.8198 - val_loss: 434.8720\n",
            "Epoch 21/1000\n",
            "40/40 - 1s - loss: 333.8448 - val_loss: 440.0217\n",
            "Epoch 22/1000\n",
            "40/40 - 1s - loss: 331.2693 - val_loss: 436.5908\n",
            "Epoch 23/1000\n",
            "40/40 - 1s - loss: 334.4665 - val_loss: 437.5753\n",
            "Epoch 24/1000\n",
            "40/40 - 1s - loss: 328.9060 - val_loss: 433.8861\n",
            "Epoch 25/1000\n",
            "40/40 - 1s - loss: 325.6028 - val_loss: 434.6876\n",
            "Epoch 26/1000\n",
            "40/40 - 1s - loss: 325.4528 - val_loss: 440.9001\n",
            "Epoch 27/1000\n",
            "40/40 - 1s - loss: 324.2015 - val_loss: 435.4167\n",
            "Epoch 28/1000\n",
            "40/40 - 1s - loss: 321.0941 - val_loss: 443.4529\n",
            "Epoch 29/1000\n",
            "40/40 - 1s - loss: 319.2975 - val_loss: 437.0361\n",
            "Epoch 30/1000\n",
            "40/40 - 1s - loss: 315.5656 - val_loss: 437.5849\n",
            "Epoch 31/1000\n",
            "40/40 - 1s - loss: 315.0805 - val_loss: 438.6011\n",
            "Epoch 32/1000\n",
            "40/40 - 1s - loss: 312.6571 - val_loss: 442.6755\n",
            "Epoch 33/1000\n",
            "40/40 - 1s - loss: 311.5307 - val_loss: 437.2913\n",
            "Epoch 34/1000\n",
            "40/40 - 1s - loss: 307.1372 - val_loss: 448.6393\n",
            "Epoch 35/1000\n",
            "40/40 - 1s - loss: 306.1461 - val_loss: 442.3180\n",
            "Epoch 36/1000\n",
            "40/40 - 1s - loss: 303.8251 - val_loss: 442.0050\n",
            "Epoch 37/1000\n",
            "40/40 - 1s - loss: 299.4301 - val_loss: 443.9288\n",
            "Epoch 38/1000\n",
            "40/40 - 1s - loss: 295.9995 - val_loss: 446.3900\n",
            "Epoch 39/1000\n",
            "40/40 - 1s - loss: 292.4763 - val_loss: 443.9630\n",
            "Epoch 40/1000\n",
            "40/40 - 1s - loss: 289.3301 - val_loss: 441.1826\n",
            "Epoch 41/1000\n",
            "40/40 - 1s - loss: 286.3420 - val_loss: 452.9100\n",
            "Epoch 42/1000\n",
            "40/40 - 1s - loss: 283.7184 - val_loss: 449.5363\n",
            "Epoch 43/1000\n",
            "40/40 - 1s - loss: 277.5468 - val_loss: 446.5175\n",
            "Epoch 44/1000\n",
            "40/40 - 1s - loss: 272.4073 - val_loss: 441.2658\n",
            "Epoch 45/1000\n",
            "40/40 - 1s - loss: 265.0919 - val_loss: 440.4852\n",
            "Epoch 46/1000\n",
            "40/40 - 1s - loss: 264.9078 - val_loss: 439.2816\n",
            "Epoch 47/1000\n",
            "40/40 - 1s - loss: 261.6665 - val_loss: 445.2092\n",
            "Epoch 48/1000\n",
            "40/40 - 1s - loss: 258.9169 - val_loss: 450.1913\n",
            "Epoch 49/1000\n",
            "40/40 - 1s - loss: 256.3180 - val_loss: 446.7198\n",
            "Epoch 50/1000\n",
            "40/40 - 1s - loss: 248.7664 - val_loss: 445.8463\n",
            "Epoch 51/1000\n",
            "40/40 - 1s - loss: 240.4857 - val_loss: 438.1331\n",
            "Epoch 52/1000\n",
            "40/40 - 1s - loss: 240.1616 - val_loss: 440.7448\n",
            "Epoch 53/1000\n",
            "40/40 - 1s - loss: 237.2317 - val_loss: 447.9661\n",
            "Epoch 54/1000\n",
            "40/40 - 1s - loss: 235.7041 - val_loss: 449.2925\n",
            "Epoch 55/1000\n",
            "40/40 - 1s - loss: 229.9953 - val_loss: 439.7815\n",
            "Epoch 56/1000\n",
            "40/40 - 1s - loss: 227.4802 - val_loss: 442.7339\n",
            "Epoch 57/1000\n",
            "40/40 - 1s - loss: 222.9949 - val_loss: 447.3111\n",
            "Epoch 58/1000\n",
            "40/40 - 1s - loss: 222.5762 - val_loss: 447.0785\n",
            "Epoch 59/1000\n",
            "40/40 - 1s - loss: 212.7583 - val_loss: 443.8948\n",
            "Epoch 60/1000\n",
            "40/40 - 1s - loss: 208.0162 - val_loss: 445.6918\n",
            "Epoch 61/1000\n",
            "40/40 - 1s - loss: 207.4566 - val_loss: 448.8609\n",
            "Epoch 62/1000\n",
            "40/40 - 1s - loss: 207.1527 - val_loss: 444.3214\n",
            "Epoch 63/1000\n",
            "40/40 - 1s - loss: 204.4901 - val_loss: 445.6158\n",
            "Epoch 64/1000\n",
            "40/40 - 1s - loss: 202.3357 - val_loss: 445.2263\n",
            "Epoch 65/1000\n",
            "40/40 - 1s - loss: 195.7359 - val_loss: 450.0015\n",
            "Epoch 66/1000\n",
            "40/40 - 1s - loss: 187.7326 - val_loss: 452.8763\n",
            "Epoch 67/1000\n",
            "40/40 - 1s - loss: 188.6325 - val_loss: 452.5019\n",
            "Epoch 68/1000\n",
            "40/40 - 1s - loss: 185.8696 - val_loss: 451.1680\n",
            "Epoch 69/1000\n",
            "40/40 - 1s - loss: 181.0826 - val_loss: 453.0774\n",
            "Epoch 70/1000\n",
            "40/40 - 1s - loss: 182.6154 - val_loss: 451.8908\n",
            "Epoch 71/1000\n",
            "40/40 - 1s - loss: 177.3885 - val_loss: 456.2096\n",
            "Epoch 72/1000\n",
            "40/40 - 1s - loss: 173.7934 - val_loss: 451.6141\n",
            "Epoch 73/1000\n",
            "40/40 - 1s - loss: 171.0267 - val_loss: 457.2621\n",
            "Epoch 74/1000\n",
            "40/40 - 1s - loss: 165.8631 - val_loss: 453.6902\n",
            "Epoch 75/1000\n",
            "40/40 - 1s - loss: 163.8908 - val_loss: 453.6940\n",
            "Epoch 76/1000\n",
            "40/40 - 1s - loss: 162.7845 - val_loss: 457.1154\n",
            "Epoch 77/1000\n",
            "40/40 - 1s - loss: 158.9065 - val_loss: 453.9763\n",
            "Epoch 78/1000\n",
            "40/40 - 1s - loss: 156.7410 - val_loss: 462.7165\n",
            "Epoch 79/1000\n",
            "40/40 - 1s - loss: 152.6821 - val_loss: 459.5072\n",
            "Epoch 80/1000\n",
            "40/40 - 1s - loss: 150.3845 - val_loss: 461.2725\n",
            "Epoch 81/1000\n",
            "40/40 - 1s - loss: 151.3561 - val_loss: 457.2831\n",
            "Epoch 82/1000\n",
            "40/40 - 1s - loss: 150.3501 - val_loss: 458.8115\n",
            "Epoch 83/1000\n",
            "40/40 - 1s - loss: 144.3500 - val_loss: 447.9747\n",
            "Epoch 84/1000\n",
            "40/40 - 1s - loss: 144.1682 - val_loss: 466.5076\n",
            "Epoch 85/1000\n",
            "40/40 - 1s - loss: 142.9211 - val_loss: 465.7829\n",
            "Epoch 86/1000\n",
            "40/40 - 1s - loss: 140.7315 - val_loss: 459.9049\n",
            "Epoch 87/1000\n",
            "40/40 - 1s - loss: 136.6490 - val_loss: 468.5255\n",
            "Epoch 88/1000\n",
            "40/40 - 1s - loss: 136.2402 - val_loss: 478.3330\n",
            "Epoch 89/1000\n",
            "40/40 - 1s - loss: 131.4970 - val_loss: 453.4184\n",
            "Epoch 90/1000\n",
            "40/40 - 1s - loss: 128.2872 - val_loss: 464.5846\n",
            "Epoch 91/1000\n",
            "40/40 - 1s - loss: 125.6013 - val_loss: 468.2292\n",
            "Epoch 92/1000\n",
            "40/40 - 1s - loss: 124.2643 - val_loss: 466.7195\n",
            "Epoch 93/1000\n",
            "40/40 - 1s - loss: 120.8033 - val_loss: 456.6681\n",
            "Epoch 94/1000\n",
            "40/40 - 1s - loss: 120.9049 - val_loss: 464.0231\n",
            "Epoch 95/1000\n",
            "40/40 - 1s - loss: 124.2811 - val_loss: 463.4576\n",
            "Epoch 96/1000\n",
            "40/40 - 1s - loss: 122.1235 - val_loss: 453.6978\n",
            "Epoch 97/1000\n",
            "40/40 - 1s - loss: 115.8104 - val_loss: 477.4958\n",
            "Epoch 98/1000\n",
            "40/40 - 1s - loss: 113.5956 - val_loss: 475.0869\n",
            "Epoch 99/1000\n",
            "40/40 - 1s - loss: 114.0712 - val_loss: 478.1038\n",
            "Epoch 100/1000\n",
            "40/40 - 1s - loss: 110.3701 - val_loss: 477.2061\n",
            "Epoch 101/1000\n",
            "40/40 - 1s - loss: 108.1056 - val_loss: 471.0565\n",
            "Epoch 102/1000\n",
            "40/40 - 1s - loss: 103.8145 - val_loss: 467.8551\n",
            "Epoch 103/1000\n",
            "40/40 - 1s - loss: 102.6000 - val_loss: 472.5367\n",
            "Epoch 104/1000\n",
            "40/40 - 1s - loss: 102.5166 - val_loss: 467.6650\n",
            "Epoch 105/1000\n",
            "40/40 - 1s - loss: 100.6820 - val_loss: 474.7532\n",
            "Epoch 106/1000\n",
            "40/40 - 1s - loss: 102.0405 - val_loss: 468.5081\n",
            "Epoch 107/1000\n",
            "40/40 - 1s - loss: 96.8619 - val_loss: 468.5509\n",
            "Epoch 108/1000\n",
            "40/40 - 1s - loss: 95.6375 - val_loss: 466.2061\n",
            "Epoch 109/1000\n",
            "40/40 - 1s - loss: 96.9407 - val_loss: 472.8342\n",
            "Epoch 110/1000\n",
            "40/40 - 1s - loss: 94.2642 - val_loss: 468.5942\n",
            "Epoch 111/1000\n",
            "40/40 - 1s - loss: 88.7234 - val_loss: 472.3381\n",
            "Epoch 112/1000\n",
            "40/40 - 1s - loss: 94.9180 - val_loss: 474.3687\n",
            "Epoch 113/1000\n",
            "40/40 - 1s - loss: 93.4782 - val_loss: 480.6277\n",
            "Epoch 114/1000\n",
            "40/40 - 1s - loss: 94.6873 - val_loss: 471.8947\n",
            "Epoch 115/1000\n",
            "40/40 - 1s - loss: 95.8032 - val_loss: 476.3083\n",
            "Epoch 116/1000\n",
            "40/40 - 1s - loss: 91.5914 - val_loss: 468.0214\n",
            "Epoch 117/1000\n",
            "40/40 - 1s - loss: 89.6508 - val_loss: 472.7112\n",
            "Epoch 118/1000\n",
            "40/40 - 1s - loss: 88.2827 - val_loss: 470.5963\n",
            "Epoch 119/1000\n",
            "40/40 - 1s - loss: 85.5220 - val_loss: 462.1226\n",
            "Epoch 120/1000\n",
            "40/40 - 1s - loss: 84.0676 - val_loss: 468.2185\n",
            "Epoch 121/1000\n",
            "40/40 - 1s - loss: 85.5614 - val_loss: 484.0776\n",
            "Epoch 122/1000\n",
            "40/40 - 1s - loss: 85.8123 - val_loss: 470.7220\n",
            "Epoch 123/1000\n",
            "40/40 - 1s - loss: 88.2194 - val_loss: 478.2813\n",
            "Epoch 124/1000\n",
            "40/40 - 1s - loss: 86.9736 - val_loss: 473.8362\n",
            "Epoch 125/1000\n",
            "40/40 - 1s - loss: 81.6715 - val_loss: 475.5517\n",
            "Epoch 126/1000\n",
            "40/40 - 1s - loss: 86.0101 - val_loss: 471.8507\n",
            "Epoch 127/1000\n",
            "40/40 - 1s - loss: 85.1977 - val_loss: 470.5086\n",
            "Epoch 128/1000\n",
            "40/40 - 1s - loss: 84.6569 - val_loss: 474.3470\n",
            "Epoch 129/1000\n",
            "40/40 - 1s - loss: 81.6200 - val_loss: 478.7850\n",
            "Epoch 130/1000\n",
            "40/40 - 1s - loss: 82.4447 - val_loss: 479.6706\n",
            "Epoch 131/1000\n",
            "40/40 - 1s - loss: 78.2064 - val_loss: 474.0659\n",
            "Epoch 132/1000\n",
            "40/40 - 1s - loss: 80.4224 - val_loss: 473.0631\n",
            "Epoch 133/1000\n",
            "40/40 - 1s - loss: 80.2526 - val_loss: 471.4979\n",
            "Epoch 134/1000\n",
            "40/40 - 1s - loss: 76.2180 - val_loss: 473.4419\n",
            "Epoch 135/1000\n",
            "40/40 - 1s - loss: 75.8571 - val_loss: 474.6353\n",
            "Epoch 136/1000\n",
            "40/40 - 1s - loss: 75.5118 - val_loss: 478.0179\n",
            "Epoch 137/1000\n",
            "40/40 - 1s - loss: 75.3043 - val_loss: 472.7114\n",
            "Epoch 138/1000\n",
            "40/40 - 1s - loss: 75.0696 - val_loss: 468.0096\n",
            "Epoch 139/1000\n",
            "40/40 - 1s - loss: 71.1303 - val_loss: 467.1476\n",
            "Epoch 140/1000\n",
            "40/40 - 1s - loss: 71.6546 - val_loss: 471.6024\n",
            "Epoch 141/1000\n",
            "40/40 - 1s - loss: 75.3153 - val_loss: 478.9538\n",
            "Epoch 142/1000\n",
            "40/40 - 1s - loss: 71.7270 - val_loss: 485.1707\n",
            "Epoch 143/1000\n",
            "40/40 - 1s - loss: 78.5316 - val_loss: 473.6180\n",
            "Epoch 144/1000\n",
            "40/40 - 1s - loss: 76.5832 - val_loss: 473.6432\n",
            "Epoch 145/1000\n",
            "40/40 - 1s - loss: 75.4050 - val_loss: 486.3932\n",
            "Epoch 146/1000\n",
            "40/40 - 1s - loss: 76.1665 - val_loss: 470.3302\n",
            "Epoch 147/1000\n",
            "40/40 - 1s - loss: 72.0897 - val_loss: 474.0138\n",
            "Epoch 148/1000\n",
            "40/40 - 1s - loss: 73.2227 - val_loss: 476.7151\n",
            "Epoch 149/1000\n",
            "40/40 - 1s - loss: 73.0611 - val_loss: 473.2635\n",
            "Epoch 150/1000\n",
            "40/40 - 1s - loss: 75.0925 - val_loss: 480.3997\n",
            "Epoch 151/1000\n",
            "40/40 - 1s - loss: 76.9360 - val_loss: 468.5263\n",
            "Epoch 152/1000\n",
            "40/40 - 1s - loss: 74.1062 - val_loss: 469.5437\n",
            "Epoch 153/1000\n",
            "40/40 - 1s - loss: 73.1266 - val_loss: 474.9535\n",
            "Epoch 154/1000\n",
            "40/40 - 1s - loss: 70.3171 - val_loss: 478.6370\n",
            "Epoch 155/1000\n",
            "40/40 - 1s - loss: 74.7764 - val_loss: 479.5473\n",
            "Epoch 156/1000\n",
            "40/40 - 1s - loss: 70.0000 - val_loss: 468.0552\n",
            "Epoch 157/1000\n",
            "40/40 - 1s - loss: 72.6497 - val_loss: 472.2384\n",
            "Epoch 158/1000\n",
            "40/40 - 1s - loss: 70.4934 - val_loss: 485.7368\n",
            "Epoch 159/1000\n",
            "40/40 - 1s - loss: 70.5823 - val_loss: 474.4094\n",
            "Epoch 160/1000\n",
            "40/40 - 1s - loss: 71.0308 - val_loss: 488.4496\n",
            "Epoch 161/1000\n",
            "40/40 - 1s - loss: 69.4280 - val_loss: 475.3233\n",
            "Epoch 162/1000\n",
            "40/40 - 1s - loss: 71.1003 - val_loss: 473.7845\n",
            "Epoch 163/1000\n",
            "40/40 - 1s - loss: 69.2134 - val_loss: 479.0620\n",
            "Epoch 164/1000\n",
            "40/40 - 1s - loss: 67.2343 - val_loss: 470.5152\n",
            "Epoch 165/1000\n",
            "40/40 - 1s - loss: 66.9915 - val_loss: 475.0191\n",
            "Epoch 166/1000\n",
            "40/40 - 1s - loss: 67.4325 - val_loss: 465.6905\n",
            "Epoch 167/1000\n",
            "40/40 - 1s - loss: 65.2581 - val_loss: 473.5023\n",
            "Epoch 168/1000\n",
            "40/40 - 1s - loss: 64.0957 - val_loss: 474.2793\n",
            "Epoch 169/1000\n",
            "40/40 - 1s - loss: 67.3993 - val_loss: 467.3573\n",
            "Epoch 170/1000\n",
            "40/40 - 1s - loss: 68.6595 - val_loss: 476.8971\n",
            "Epoch 171/1000\n",
            "40/40 - 1s - loss: 66.8897 - val_loss: 474.1838\n",
            "Epoch 172/1000\n",
            "40/40 - 1s - loss: 64.7068 - val_loss: 471.3009\n",
            "Epoch 173/1000\n",
            "40/40 - 1s - loss: 67.7972 - val_loss: 467.8342\n",
            "Epoch 174/1000\n",
            "40/40 - 1s - loss: 66.1029 - val_loss: 473.7025\n",
            "Epoch 175/1000\n",
            "40/40 - 1s - loss: 64.3192 - val_loss: 472.8172\n",
            "Epoch 176/1000\n",
            "40/40 - 1s - loss: 66.1931 - val_loss: 475.7502\n",
            "Epoch 177/1000\n",
            "40/40 - 1s - loss: 62.9888 - val_loss: 474.2498\n",
            "Epoch 178/1000\n",
            "40/40 - 1s - loss: 65.4741 - val_loss: 470.5790\n",
            "Epoch 179/1000\n",
            "40/40 - 1s - loss: 67.3477 - val_loss: 473.7484\n",
            "Epoch 180/1000\n",
            "40/40 - 1s - loss: 70.2283 - val_loss: 475.0416\n",
            "Epoch 181/1000\n",
            "40/40 - 1s - loss: 64.1357 - val_loss: 473.3580\n",
            "Epoch 182/1000\n",
            "40/40 - 1s - loss: 65.6566 - val_loss: 471.4980\n",
            "Epoch 183/1000\n",
            "40/40 - 1s - loss: 62.0688 - val_loss: 477.9809\n",
            "Epoch 184/1000\n",
            "40/40 - 1s - loss: 61.9431 - val_loss: 475.5555\n",
            "Epoch 185/1000\n",
            "40/40 - 1s - loss: 64.8878 - val_loss: 466.7748\n",
            "Epoch 186/1000\n",
            "40/40 - 1s - loss: 62.7000 - val_loss: 463.9549\n",
            "Epoch 187/1000\n",
            "40/40 - 1s - loss: 64.6364 - val_loss: 468.6115\n",
            "Epoch 188/1000\n",
            "40/40 - 1s - loss: 67.3375 - val_loss: 476.2253\n",
            "Epoch 189/1000\n",
            "40/40 - 1s - loss: 67.1825 - val_loss: 476.7948\n",
            "Epoch 190/1000\n",
            "40/40 - 1s - loss: 65.0221 - val_loss: 467.0969\n",
            "Epoch 191/1000\n",
            "40/40 - 1s - loss: 63.4016 - val_loss: 471.7621\n",
            "Epoch 192/1000\n",
            "40/40 - 1s - loss: 63.7677 - val_loss: 475.7483\n",
            "Epoch 193/1000\n",
            "40/40 - 1s - loss: 63.7681 - val_loss: 467.5161\n",
            "Epoch 194/1000\n",
            "40/40 - 1s - loss: 63.9874 - val_loss: 471.8901\n",
            "Epoch 195/1000\n",
            "40/40 - 1s - loss: 58.8170 - val_loss: 472.3343\n",
            "Epoch 196/1000\n",
            "40/40 - 1s - loss: 65.1834 - val_loss: 468.5962\n",
            "Epoch 197/1000\n",
            "40/40 - 1s - loss: 64.6588 - val_loss: 467.3849\n",
            "Epoch 198/1000\n",
            "40/40 - 1s - loss: 61.4712 - val_loss: 468.7325\n",
            "Epoch 199/1000\n",
            "40/40 - 1s - loss: 63.4181 - val_loss: 481.5638\n",
            "Epoch 200/1000\n",
            "40/40 - 1s - loss: 63.4792 - val_loss: 466.9166\n",
            "Epoch 201/1000\n",
            "40/40 - 1s - loss: 61.9946 - val_loss: 479.6789\n",
            "Epoch 202/1000\n",
            "40/40 - 1s - loss: 59.7450 - val_loss: 476.6297\n",
            "Epoch 203/1000\n",
            "40/40 - 1s - loss: 62.0690 - val_loss: 476.6648\n",
            "Epoch 204/1000\n",
            "40/40 - 1s - loss: 61.7771 - val_loss: 476.8641\n",
            "Epoch 205/1000\n",
            "40/40 - 1s - loss: 60.9934 - val_loss: 476.2484\n",
            "Epoch 206/1000\n",
            "40/40 - 1s - loss: 57.7943 - val_loss: 473.3854\n",
            "Epoch 207/1000\n",
            "40/40 - 1s - loss: 60.6714 - val_loss: 468.2979\n",
            "Epoch 208/1000\n",
            "40/40 - 1s - loss: 61.4902 - val_loss: 476.8155\n",
            "Epoch 209/1000\n",
            "40/40 - 1s - loss: 58.4661 - val_loss: 471.3091\n",
            "Epoch 210/1000\n",
            "40/40 - 1s - loss: 57.4777 - val_loss: 472.9070\n",
            "Epoch 211/1000\n",
            "40/40 - 1s - loss: 57.3191 - val_loss: 469.0435\n",
            "Epoch 212/1000\n",
            "40/40 - 1s - loss: 60.7854 - val_loss: 469.6013\n",
            "Epoch 213/1000\n",
            "40/40 - 1s - loss: 60.3266 - val_loss: 475.1656\n",
            "Epoch 214/1000\n",
            "40/40 - 1s - loss: 60.8424 - val_loss: 471.2083\n",
            "Epoch 215/1000\n",
            "40/40 - 1s - loss: 62.0050 - val_loss: 475.7795\n",
            "Epoch 216/1000\n",
            "40/40 - 1s - loss: 60.0708 - val_loss: 465.8966\n",
            "Epoch 217/1000\n",
            "40/40 - 1s - loss: 59.6624 - val_loss: 469.6498\n",
            "Epoch 218/1000\n",
            "40/40 - 1s - loss: 59.9014 - val_loss: 470.3519\n",
            "Epoch 219/1000\n",
            "40/40 - 1s - loss: 57.2154 - val_loss: 472.9130\n",
            "Epoch 220/1000\n",
            "40/40 - 1s - loss: 65.5181 - val_loss: 475.0411\n",
            "Epoch 221/1000\n",
            "40/40 - 1s - loss: 61.3476 - val_loss: 462.3122\n",
            "Epoch 222/1000\n",
            "40/40 - 1s - loss: 62.5871 - val_loss: 474.4881\n",
            "Epoch 223/1000\n",
            "40/40 - 1s - loss: 59.8602 - val_loss: 477.7135\n",
            "Epoch 224/1000\n",
            "40/40 - 1s - loss: 57.6432 - val_loss: 472.7270\n",
            "Epoch 225/1000\n",
            "40/40 - 1s - loss: 61.5335 - val_loss: 476.0261\n",
            "Epoch 226/1000\n",
            "40/40 - 1s - loss: 58.5307 - val_loss: 470.4356\n",
            "Epoch 227/1000\n",
            "40/40 - 1s - loss: 55.9850 - val_loss: 476.3023\n",
            "Epoch 228/1000\n",
            "40/40 - 1s - loss: 58.8569 - val_loss: 466.6540\n",
            "Epoch 229/1000\n",
            "40/40 - 1s - loss: 54.5107 - val_loss: 473.4464\n",
            "Epoch 230/1000\n",
            "40/40 - 1s - loss: 57.9603 - val_loss: 475.1189\n",
            "Epoch 231/1000\n",
            "40/40 - 1s - loss: 54.4653 - val_loss: 471.3847\n",
            "Epoch 232/1000\n",
            "40/40 - 1s - loss: 54.9934 - val_loss: 472.7306\n",
            "Epoch 233/1000\n",
            "40/40 - 1s - loss: 55.7245 - val_loss: 474.1855\n",
            "Epoch 234/1000\n",
            "40/40 - 1s - loss: 57.5537 - val_loss: 473.6483\n",
            "Epoch 235/1000\n",
            "40/40 - 1s - loss: 58.1485 - val_loss: 473.7296\n",
            "Epoch 236/1000\n",
            "40/40 - 1s - loss: 59.3209 - val_loss: 471.9483\n",
            "Epoch 237/1000\n",
            "40/40 - 1s - loss: 57.7107 - val_loss: 465.8812\n",
            "Epoch 238/1000\n",
            "40/40 - 1s - loss: 55.1858 - val_loss: 466.3033\n",
            "Epoch 239/1000\n",
            "40/40 - 1s - loss: 56.8828 - val_loss: 467.1585\n",
            "Epoch 240/1000\n",
            "40/40 - 1s - loss: 58.3774 - val_loss: 466.1578\n",
            "Epoch 241/1000\n",
            "40/40 - 1s - loss: 63.6373 - val_loss: 467.8337\n",
            "Epoch 242/1000\n",
            "40/40 - 1s - loss: 61.1040 - val_loss: 466.8428\n",
            "Epoch 243/1000\n",
            "40/40 - 1s - loss: 56.8811 - val_loss: 477.9401\n",
            "Epoch 244/1000\n",
            "40/40 - 1s - loss: 59.2911 - val_loss: 477.6868\n",
            "Epoch 245/1000\n",
            "40/40 - 1s - loss: 54.7866 - val_loss: 476.8513\n",
            "Epoch 246/1000\n",
            "40/40 - 1s - loss: 58.3229 - val_loss: 474.2933\n",
            "Epoch 247/1000\n",
            "40/40 - 1s - loss: 58.3881 - val_loss: 472.2423\n",
            "Epoch 248/1000\n",
            "40/40 - 1s - loss: 61.4200 - val_loss: 478.7354\n",
            "Epoch 249/1000\n",
            "40/40 - 1s - loss: 56.7589 - val_loss: 473.6671\n",
            "Epoch 250/1000\n",
            "40/40 - 1s - loss: 56.1191 - val_loss: 472.0692\n",
            "Epoch 251/1000\n",
            "40/40 - 1s - loss: 54.5690 - val_loss: 473.4166\n",
            "Epoch 252/1000\n",
            "40/40 - 1s - loss: 53.6398 - val_loss: 468.9149\n",
            "Epoch 253/1000\n",
            "40/40 - 1s - loss: 55.9846 - val_loss: 478.7291\n",
            "Epoch 254/1000\n",
            "40/40 - 1s - loss: 57.9241 - val_loss: 467.2290\n",
            "Epoch 255/1000\n",
            "40/40 - 1s - loss: 53.3101 - val_loss: 474.6737\n",
            "Epoch 256/1000\n",
            "40/40 - 1s - loss: 62.5172 - val_loss: 469.0376\n",
            "Epoch 257/1000\n",
            "40/40 - 1s - loss: 58.6441 - val_loss: 478.4670\n",
            "Epoch 258/1000\n",
            "40/40 - 1s - loss: 60.1803 - val_loss: 475.2580\n",
            "Epoch 259/1000\n",
            "40/40 - 1s - loss: 56.3672 - val_loss: 471.2289\n",
            "Epoch 260/1000\n",
            "40/40 - 1s - loss: 53.7243 - val_loss: 472.4574\n",
            "Epoch 261/1000\n",
            "40/40 - 1s - loss: 57.7255 - val_loss: 475.4782\n",
            "Epoch 262/1000\n",
            "40/40 - 1s - loss: 57.4295 - val_loss: 467.8341\n",
            "Epoch 263/1000\n",
            "40/40 - 1s - loss: 64.6818 - val_loss: 486.4791\n",
            "Epoch 264/1000\n",
            "40/40 - 1s - loss: 60.0128 - val_loss: 483.1860\n",
            "Epoch 265/1000\n",
            "40/40 - 1s - loss: 59.1534 - val_loss: 471.2725\n",
            "Epoch 266/1000\n",
            "40/40 - 1s - loss: 52.0765 - val_loss: 469.9299\n",
            "Epoch 267/1000\n",
            "40/40 - 1s - loss: 54.1186 - val_loss: 468.8575\n",
            "Epoch 268/1000\n",
            "40/40 - 1s - loss: 50.9101 - val_loss: 466.8693\n",
            "Epoch 269/1000\n",
            "40/40 - 1s - loss: 56.6807 - val_loss: 468.2077\n",
            "Epoch 270/1000\n",
            "40/40 - 1s - loss: 55.8892 - val_loss: 475.2431\n",
            "Epoch 271/1000\n",
            "40/40 - 1s - loss: 51.8117 - val_loss: 467.9684\n",
            "Epoch 272/1000\n",
            "40/40 - 1s - loss: 52.4137 - val_loss: 473.7719\n",
            "Epoch 273/1000\n",
            "40/40 - 1s - loss: 55.6779 - val_loss: 473.6425\n",
            "Epoch 274/1000\n",
            "40/40 - 1s - loss: 53.7376 - val_loss: 471.1118\n",
            "Epoch 275/1000\n",
            "40/40 - 1s - loss: 54.6977 - val_loss: 468.9817\n",
            "Epoch 276/1000\n",
            "40/40 - 1s - loss: 53.9553 - val_loss: 467.9294\n",
            "Epoch 277/1000\n",
            "40/40 - 1s - loss: 52.0541 - val_loss: 471.9541\n",
            "Epoch 278/1000\n",
            "40/40 - 1s - loss: 51.1053 - val_loss: 467.2220\n",
            "Epoch 279/1000\n",
            "40/40 - 1s - loss: 52.0115 - val_loss: 474.7560\n",
            "Epoch 280/1000\n",
            "40/40 - 1s - loss: 52.2985 - val_loss: 470.1307\n",
            "Epoch 281/1000\n",
            "40/40 - 1s - loss: 51.8747 - val_loss: 470.4833\n",
            "Epoch 282/1000\n",
            "40/40 - 1s - loss: 53.3260 - val_loss: 467.4446\n",
            "Epoch 283/1000\n",
            "40/40 - 1s - loss: 51.0015 - val_loss: 472.8017\n",
            "Epoch 284/1000\n",
            "40/40 - 1s - loss: 47.5497 - val_loss: 465.8395\n",
            "Epoch 285/1000\n",
            "40/40 - 1s - loss: 48.0346 - val_loss: 473.1234\n",
            "Epoch 286/1000\n",
            "40/40 - 1s - loss: 52.5328 - val_loss: 464.5454\n",
            "Epoch 287/1000\n",
            "40/40 - 1s - loss: 47.7923 - val_loss: 474.9872\n",
            "Epoch 288/1000\n",
            "40/40 - 1s - loss: 52.4843 - val_loss: 472.2761\n",
            "Epoch 289/1000\n",
            "40/40 - 1s - loss: 52.7296 - val_loss: 469.9183\n",
            "Epoch 290/1000\n",
            "40/40 - 1s - loss: 51.0811 - val_loss: 472.5992\n",
            "Epoch 291/1000\n",
            "40/40 - 1s - loss: 50.5065 - val_loss: 472.4228\n",
            "Epoch 292/1000\n",
            "40/40 - 1s - loss: 49.4561 - val_loss: 474.6596\n",
            "Epoch 293/1000\n",
            "40/40 - 1s - loss: 48.5932 - val_loss: 474.0130\n",
            "Epoch 294/1000\n",
            "40/40 - 1s - loss: 49.4638 - val_loss: 468.4461\n",
            "Epoch 295/1000\n",
            "40/40 - 1s - loss: 50.7239 - val_loss: 473.6195\n",
            "Epoch 296/1000\n",
            "40/40 - 1s - loss: 50.2257 - val_loss: 473.4948\n",
            "Epoch 297/1000\n",
            "40/40 - 1s - loss: 51.5938 - val_loss: 469.0745\n",
            "Epoch 298/1000\n",
            "40/40 - 1s - loss: 49.0751 - val_loss: 465.7185\n",
            "Epoch 299/1000\n",
            "40/40 - 1s - loss: 49.8732 - val_loss: 458.0389\n",
            "Epoch 300/1000\n",
            "40/40 - 1s - loss: 48.9577 - val_loss: 468.4885\n",
            "Epoch 301/1000\n",
            "40/40 - 1s - loss: 48.0968 - val_loss: 462.1240\n",
            "Epoch 302/1000\n",
            "40/40 - 1s - loss: 51.8937 - val_loss: 465.7708\n",
            "Epoch 303/1000\n",
            "40/40 - 1s - loss: 48.2255 - val_loss: 454.1989\n",
            "Epoch 304/1000\n",
            "40/40 - 1s - loss: 50.8572 - val_loss: 463.0295\n",
            "Epoch 305/1000\n",
            "40/40 - 1s - loss: 48.6478 - val_loss: 469.1371\n",
            "Epoch 306/1000\n",
            "40/40 - 1s - loss: 48.1766 - val_loss: 460.4103\n",
            "Epoch 307/1000\n",
            "40/40 - 1s - loss: 49.5418 - val_loss: 459.5619\n",
            "Epoch 308/1000\n",
            "40/40 - 1s - loss: 52.8293 - val_loss: 465.6824\n",
            "Epoch 309/1000\n",
            "40/40 - 1s - loss: 49.8735 - val_loss: 462.1520\n",
            "Epoch 310/1000\n",
            "40/40 - 1s - loss: 49.3221 - val_loss: 469.7921\n",
            "Epoch 311/1000\n",
            "40/40 - 1s - loss: 51.2894 - val_loss: 470.4150\n",
            "Epoch 312/1000\n",
            "40/40 - 1s - loss: 48.2661 - val_loss: 465.8902\n",
            "Epoch 313/1000\n",
            "40/40 - 1s - loss: 47.1132 - val_loss: 468.6243\n",
            "Epoch 314/1000\n",
            "40/40 - 1s - loss: 45.3781 - val_loss: 468.8248\n",
            "Epoch 315/1000\n",
            "40/40 - 1s - loss: 48.7785 - val_loss: 466.2643\n",
            "Epoch 316/1000\n",
            "40/40 - 1s - loss: 50.0547 - val_loss: 469.4424\n",
            "Epoch 317/1000\n",
            "40/40 - 1s - loss: 47.4241 - val_loss: 464.6879\n",
            "Epoch 318/1000\n",
            "40/40 - 1s - loss: 47.3821 - val_loss: 460.0266\n",
            "Epoch 319/1000\n",
            "40/40 - 1s - loss: 47.3699 - val_loss: 465.3611\n",
            "Epoch 320/1000\n",
            "40/40 - 1s - loss: 47.3031 - val_loss: 462.8056\n",
            "Epoch 321/1000\n",
            "40/40 - 1s - loss: 48.3230 - val_loss: 462.6034\n",
            "Epoch 322/1000\n",
            "40/40 - 1s - loss: 48.0082 - val_loss: 466.0685\n",
            "Epoch 323/1000\n",
            "40/40 - 1s - loss: 44.0307 - val_loss: 466.8938\n",
            "Epoch 324/1000\n",
            "40/40 - 1s - loss: 45.1211 - val_loss: 475.9247\n",
            "Epoch 325/1000\n",
            "40/40 - 1s - loss: 46.8257 - val_loss: 462.5512\n",
            "Epoch 326/1000\n",
            "40/40 - 1s - loss: 47.6693 - val_loss: 464.5212\n",
            "Epoch 327/1000\n",
            "40/40 - 1s - loss: 44.5192 - val_loss: 464.0621\n",
            "Epoch 328/1000\n",
            "40/40 - 1s - loss: 45.1877 - val_loss: 463.3966\n",
            "Epoch 329/1000\n",
            "40/40 - 1s - loss: 44.0116 - val_loss: 463.8753\n",
            "Epoch 330/1000\n",
            "40/40 - 1s - loss: 45.6936 - val_loss: 461.0987\n",
            "Epoch 331/1000\n",
            "40/40 - 1s - loss: 49.9826 - val_loss: 463.5669\n",
            "Epoch 332/1000\n",
            "40/40 - 1s - loss: 48.6115 - val_loss: 460.6499\n",
            "Epoch 333/1000\n",
            "40/40 - 1s - loss: 47.6326 - val_loss: 464.9540\n",
            "Epoch 334/1000\n",
            "40/40 - 1s - loss: 48.1657 - val_loss: 468.3972\n",
            "Epoch 335/1000\n",
            "40/40 - 1s - loss: 45.3769 - val_loss: 465.8908\n",
            "Epoch 336/1000\n",
            "40/40 - 1s - loss: 45.7740 - val_loss: 470.0000\n",
            "Epoch 337/1000\n",
            "40/40 - 1s - loss: 48.6413 - val_loss: 462.7494\n",
            "Epoch 338/1000\n",
            "40/40 - 1s - loss: 46.1127 - val_loss: 463.1160\n",
            "Epoch 339/1000\n",
            "40/40 - 1s - loss: 47.5080 - val_loss: 469.2251\n",
            "Epoch 340/1000\n",
            "40/40 - 1s - loss: 48.1489 - val_loss: 467.5327\n",
            "Epoch 341/1000\n",
            "40/40 - 1s - loss: 46.7888 - val_loss: 466.4281\n",
            "Epoch 342/1000\n",
            "40/40 - 1s - loss: 45.0741 - val_loss: 470.7041\n",
            "Epoch 343/1000\n",
            "40/40 - 1s - loss: 42.3312 - val_loss: 468.1240\n",
            "Epoch 344/1000\n",
            "40/40 - 1s - loss: 43.4511 - val_loss: 462.1247\n",
            "Epoch 345/1000\n",
            "40/40 - 1s - loss: 45.4708 - val_loss: 467.1403\n",
            "Epoch 346/1000\n",
            "40/40 - 1s - loss: 44.4217 - val_loss: 464.4940\n",
            "Epoch 347/1000\n",
            "40/40 - 1s - loss: 43.8199 - val_loss: 472.5801\n",
            "Epoch 348/1000\n",
            "40/40 - 1s - loss: 44.0604 - val_loss: 470.4135\n",
            "Epoch 349/1000\n",
            "40/40 - 1s - loss: 44.6630 - val_loss: 464.8105\n",
            "Epoch 350/1000\n",
            "40/40 - 1s - loss: 48.2319 - val_loss: 463.4915\n",
            "Epoch 351/1000\n",
            "40/40 - 1s - loss: 48.2519 - val_loss: 465.6559\n",
            "Epoch 352/1000\n",
            "40/40 - 1s - loss: 46.8109 - val_loss: 469.8657\n",
            "Epoch 353/1000\n",
            "40/40 - 1s - loss: 45.7251 - val_loss: 466.3504\n",
            "Epoch 354/1000\n",
            "40/40 - 1s - loss: 43.9642 - val_loss: 462.0430\n",
            "Epoch 355/1000\n",
            "40/40 - 1s - loss: 47.7053 - val_loss: 467.7864\n",
            "Epoch 356/1000\n",
            "40/40 - 1s - loss: 47.8552 - val_loss: 466.1323\n",
            "Epoch 357/1000\n",
            "40/40 - 1s - loss: 44.8918 - val_loss: 467.3238\n",
            "Epoch 358/1000\n",
            "40/40 - 1s - loss: 46.5072 - val_loss: 463.4659\n",
            "Epoch 359/1000\n",
            "40/40 - 1s - loss: 45.2599 - val_loss: 465.5415\n",
            "Epoch 360/1000\n",
            "40/40 - 1s - loss: 43.4785 - val_loss: 467.4594\n",
            "Epoch 361/1000\n",
            "40/40 - 1s - loss: 46.3847 - val_loss: 468.0816\n",
            "Epoch 362/1000\n",
            "40/40 - 1s - loss: 45.7869 - val_loss: 467.5939\n",
            "Epoch 363/1000\n",
            "40/40 - 1s - loss: 45.7804 - val_loss: 462.3815\n",
            "Epoch 364/1000\n",
            "40/40 - 1s - loss: 44.2233 - val_loss: 463.2081\n",
            "Epoch 365/1000\n",
            "40/40 - 1s - loss: 44.0701 - val_loss: 467.0289\n",
            "Epoch 366/1000\n",
            "40/40 - 1s - loss: 44.5610 - val_loss: 467.7988\n",
            "Epoch 367/1000\n",
            "40/40 - 1s - loss: 43.0850 - val_loss: 471.2107\n",
            "Epoch 368/1000\n",
            "40/40 - 1s - loss: 44.8379 - val_loss: 456.1389\n",
            "Epoch 369/1000\n",
            "40/40 - 1s - loss: 45.8482 - val_loss: 467.3511\n",
            "Epoch 370/1000\n",
            "40/40 - 1s - loss: 45.9097 - val_loss: 468.7633\n",
            "Epoch 371/1000\n",
            "40/40 - 1s - loss: 42.7707 - val_loss: 466.9333\n",
            "Epoch 372/1000\n",
            "40/40 - 1s - loss: 43.3889 - val_loss: 463.7793\n",
            "Epoch 373/1000\n",
            "40/40 - 1s - loss: 43.8737 - val_loss: 466.5235\n",
            "Epoch 374/1000\n",
            "40/40 - 1s - loss: 44.9046 - val_loss: 466.6177\n",
            "Epoch 375/1000\n",
            "40/40 - 1s - loss: 44.0884 - val_loss: 465.1638\n",
            "Epoch 376/1000\n",
            "40/40 - 1s - loss: 46.2336 - val_loss: 467.9016\n",
            "Epoch 377/1000\n",
            "40/40 - 1s - loss: 44.6057 - val_loss: 463.2595\n",
            "Epoch 378/1000\n",
            "40/40 - 1s - loss: 43.3305 - val_loss: 467.7363\n",
            "Epoch 379/1000\n",
            "40/40 - 1s - loss: 45.5640 - val_loss: 458.1470\n",
            "Epoch 380/1000\n",
            "40/40 - 1s - loss: 43.8460 - val_loss: 467.8477\n",
            "Epoch 381/1000\n",
            "40/40 - 1s - loss: 42.9874 - val_loss: 463.5078\n",
            "Epoch 382/1000\n",
            "40/40 - 1s - loss: 41.4358 - val_loss: 468.1586\n",
            "Epoch 383/1000\n",
            "40/40 - 1s - loss: 43.4552 - val_loss: 464.2642\n",
            "Epoch 384/1000\n",
            "40/40 - 1s - loss: 44.6043 - val_loss: 460.8981\n",
            "Epoch 385/1000\n",
            "40/40 - 1s - loss: 44.7026 - val_loss: 469.1787\n",
            "Epoch 386/1000\n",
            "40/40 - 1s - loss: 47.9080 - val_loss: 465.4358\n",
            "Epoch 387/1000\n",
            "40/40 - 1s - loss: 42.3924 - val_loss: 464.6230\n",
            "Epoch 388/1000\n",
            "40/40 - 1s - loss: 41.3244 - val_loss: 464.4291\n",
            "Epoch 389/1000\n",
            "40/40 - 1s - loss: 39.7105 - val_loss: 464.6407\n",
            "Epoch 390/1000\n",
            "40/40 - 1s - loss: 41.7931 - val_loss: 476.1893\n",
            "Epoch 391/1000\n",
            "40/40 - 1s - loss: 42.3112 - val_loss: 467.0855\n",
            "Epoch 392/1000\n",
            "40/40 - 1s - loss: 40.4788 - val_loss: 459.4068\n",
            "Epoch 393/1000\n",
            "40/40 - 1s - loss: 42.9513 - val_loss: 464.8922\n",
            "Epoch 394/1000\n",
            "40/40 - 1s - loss: 42.5365 - val_loss: 471.8534\n",
            "Epoch 395/1000\n",
            "40/40 - 1s - loss: 42.5578 - val_loss: 470.8676\n",
            "Epoch 396/1000\n",
            "40/40 - 1s - loss: 43.9070 - val_loss: 466.2120\n",
            "Epoch 397/1000\n",
            "40/40 - 1s - loss: 42.9958 - val_loss: 472.5291\n",
            "Epoch 398/1000\n",
            "40/40 - 1s - loss: 40.4902 - val_loss: 465.1899\n",
            "Epoch 399/1000\n",
            "40/40 - 1s - loss: 44.7615 - val_loss: 466.2845\n",
            "Epoch 400/1000\n",
            "40/40 - 1s - loss: 40.9878 - val_loss: 460.6990\n",
            "Epoch 401/1000\n",
            "40/40 - 1s - loss: 42.1236 - val_loss: 459.5910\n",
            "Epoch 402/1000\n",
            "40/40 - 1s - loss: 44.1678 - val_loss: 464.0516\n",
            "Epoch 403/1000\n",
            "40/40 - 1s - loss: 40.2747 - val_loss: 475.3566\n",
            "Epoch 404/1000\n",
            "40/40 - 1s - loss: 42.8586 - val_loss: 465.0743\n",
            "Epoch 405/1000\n",
            "40/40 - 1s - loss: 41.7621 - val_loss: 458.3833\n",
            "Epoch 406/1000\n",
            "40/40 - 1s - loss: 42.4235 - val_loss: 470.0783\n",
            "Epoch 407/1000\n",
            "40/40 - 1s - loss: 41.9105 - val_loss: 466.5240\n",
            "Epoch 408/1000\n",
            "40/40 - 1s - loss: 42.5664 - val_loss: 475.9012\n",
            "Epoch 409/1000\n",
            "40/40 - 1s - loss: 44.8107 - val_loss: 468.2494\n",
            "Epoch 410/1000\n",
            "40/40 - 1s - loss: 42.2788 - val_loss: 467.5091\n",
            "Epoch 411/1000\n",
            "40/40 - 1s - loss: 44.0295 - val_loss: 468.8110\n",
            "Epoch 412/1000\n",
            "40/40 - 1s - loss: 39.2376 - val_loss: 465.3199\n",
            "Epoch 413/1000\n",
            "40/40 - 1s - loss: 38.9517 - val_loss: 467.5260\n",
            "Epoch 414/1000\n",
            "40/40 - 1s - loss: 44.8589 - val_loss: 467.1185\n",
            "Epoch 415/1000\n",
            "40/40 - 1s - loss: 42.4394 - val_loss: 461.0744\n",
            "Epoch 416/1000\n",
            "40/40 - 1s - loss: 41.9523 - val_loss: 472.5600\n",
            "Epoch 417/1000\n",
            "40/40 - 1s - loss: 40.8679 - val_loss: 465.1365\n",
            "Epoch 418/1000\n",
            "40/40 - 1s - loss: 40.8437 - val_loss: 469.9418\n",
            "Epoch 419/1000\n",
            "40/40 - 1s - loss: 42.6885 - val_loss: 471.5381\n",
            "Epoch 420/1000\n",
            "40/40 - 1s - loss: 42.4567 - val_loss: 470.4465\n",
            "Epoch 421/1000\n",
            "40/40 - 1s - loss: 39.5859 - val_loss: 464.4894\n",
            "Epoch 422/1000\n",
            "40/40 - 1s - loss: 40.1348 - val_loss: 469.9125\n",
            "Epoch 423/1000\n",
            "40/40 - 1s - loss: 41.0804 - val_loss: 459.3927\n",
            "Epoch 424/1000\n",
            "40/40 - 1s - loss: 41.7601 - val_loss: 464.5588\n",
            "Epoch 425/1000\n",
            "40/40 - 1s - loss: 40.1285 - val_loss: 466.9138\n",
            "Epoch 426/1000\n",
            "40/40 - 1s - loss: 40.1917 - val_loss: 473.9110\n",
            "Epoch 427/1000\n",
            "40/40 - 1s - loss: 41.6330 - val_loss: 470.1120\n",
            "Epoch 428/1000\n",
            "40/40 - 1s - loss: 39.6150 - val_loss: 464.5432\n",
            "Epoch 429/1000\n",
            "40/40 - 1s - loss: 38.9715 - val_loss: 465.4135\n",
            "Epoch 430/1000\n",
            "40/40 - 1s - loss: 43.8363 - val_loss: 469.6182\n",
            "Epoch 431/1000\n",
            "40/40 - 1s - loss: 42.1135 - val_loss: 473.3089\n",
            "Epoch 432/1000\n",
            "40/40 - 1s - loss: 38.5198 - val_loss: 472.1712\n",
            "Epoch 433/1000\n",
            "40/40 - 1s - loss: 39.7573 - val_loss: 467.6065\n",
            "Epoch 434/1000\n",
            "40/40 - 1s - loss: 40.7081 - val_loss: 472.5989\n",
            "Epoch 435/1000\n",
            "40/40 - 1s - loss: 39.6898 - val_loss: 470.2220\n",
            "Epoch 436/1000\n",
            "40/40 - 1s - loss: 40.6436 - val_loss: 467.2881\n",
            "Epoch 437/1000\n",
            "40/40 - 1s - loss: 42.1511 - val_loss: 472.0052\n",
            "Epoch 438/1000\n",
            "40/40 - 1s - loss: 44.0367 - val_loss: 477.1421\n",
            "Epoch 439/1000\n",
            "40/40 - 1s - loss: 43.9782 - val_loss: 476.1736\n",
            "Epoch 440/1000\n",
            "40/40 - 1s - loss: 37.7062 - val_loss: 466.5825\n",
            "Epoch 441/1000\n",
            "40/40 - 1s - loss: 40.6180 - val_loss: 467.9881\n",
            "Epoch 442/1000\n",
            "40/40 - 1s - loss: 42.4195 - val_loss: 474.2816\n",
            "Epoch 443/1000\n",
            "40/40 - 1s - loss: 38.3688 - val_loss: 471.5981\n",
            "Epoch 444/1000\n",
            "40/40 - 1s - loss: 37.5978 - val_loss: 468.9362\n",
            "Epoch 445/1000\n",
            "40/40 - 1s - loss: 36.4724 - val_loss: 467.0686\n",
            "Epoch 446/1000\n",
            "40/40 - 1s - loss: 37.6505 - val_loss: 465.6407\n",
            "Epoch 447/1000\n",
            "40/40 - 1s - loss: 41.2632 - val_loss: 465.2248\n",
            "Epoch 448/1000\n",
            "40/40 - 1s - loss: 40.8133 - val_loss: 474.2013\n",
            "Epoch 449/1000\n",
            "40/40 - 1s - loss: 39.4100 - val_loss: 470.4834\n",
            "Epoch 450/1000\n",
            "40/40 - 1s - loss: 41.7482 - val_loss: 469.4051\n",
            "Epoch 451/1000\n",
            "40/40 - 1s - loss: 40.3417 - val_loss: 474.2878\n",
            "Epoch 452/1000\n",
            "40/40 - 1s - loss: 39.5338 - val_loss: 472.7515\n",
            "Epoch 453/1000\n",
            "40/40 - 1s - loss: 42.2313 - val_loss: 474.1706\n",
            "Epoch 454/1000\n",
            "40/40 - 1s - loss: 38.4658 - val_loss: 476.0048\n",
            "Epoch 455/1000\n",
            "40/40 - 1s - loss: 40.1543 - val_loss: 467.0536\n",
            "Epoch 456/1000\n",
            "40/40 - 1s - loss: 40.3445 - val_loss: 470.8133\n",
            "Epoch 457/1000\n",
            "40/40 - 1s - loss: 42.7048 - val_loss: 479.9272\n",
            "Epoch 458/1000\n",
            "40/40 - 1s - loss: 39.6592 - val_loss: 471.4148\n",
            "Epoch 459/1000\n",
            "40/40 - 1s - loss: 41.0061 - val_loss: 468.8706\n",
            "Epoch 460/1000\n",
            "40/40 - 1s - loss: 39.1898 - val_loss: 466.3816\n",
            "Epoch 461/1000\n",
            "40/40 - 1s - loss: 39.9831 - val_loss: 473.3179\n",
            "Epoch 462/1000\n",
            "40/40 - 1s - loss: 37.2643 - val_loss: 471.0681\n",
            "Epoch 463/1000\n",
            "40/40 - 1s - loss: 38.3867 - val_loss: 475.8190\n",
            "Epoch 464/1000\n",
            "40/40 - 1s - loss: 36.2979 - val_loss: 469.6958\n",
            "Epoch 465/1000\n",
            "40/40 - 1s - loss: 37.4747 - val_loss: 472.5897\n",
            "Epoch 466/1000\n",
            "40/40 - 1s - loss: 39.5584 - val_loss: 472.4450\n",
            "Epoch 467/1000\n",
            "40/40 - 1s - loss: 41.6112 - val_loss: 471.3035\n",
            "Epoch 468/1000\n",
            "40/40 - 1s - loss: 39.5156 - val_loss: 478.9803\n",
            "Epoch 469/1000\n",
            "40/40 - 1s - loss: 38.1230 - val_loss: 475.4370\n",
            "Epoch 470/1000\n",
            "40/40 - 1s - loss: 38.4204 - val_loss: 467.8336\n",
            "Epoch 471/1000\n",
            "40/40 - 1s - loss: 38.6977 - val_loss: 466.3276\n",
            "Epoch 472/1000\n",
            "40/40 - 1s - loss: 43.0953 - val_loss: 470.4750\n",
            "Epoch 473/1000\n",
            "40/40 - 1s - loss: 39.5907 - val_loss: 475.9570\n",
            "Epoch 474/1000\n",
            "40/40 - 1s - loss: 38.3089 - val_loss: 466.5539\n",
            "Epoch 475/1000\n",
            "40/40 - 1s - loss: 37.1563 - val_loss: 471.9401\n",
            "Epoch 476/1000\n",
            "40/40 - 1s - loss: 39.2736 - val_loss: 474.2217\n",
            "Epoch 477/1000\n",
            "40/40 - 1s - loss: 39.7590 - val_loss: 476.8987\n",
            "Epoch 478/1000\n",
            "40/40 - 1s - loss: 39.0633 - val_loss: 477.1833\n",
            "Epoch 479/1000\n",
            "40/40 - 1s - loss: 40.4229 - val_loss: 470.0150\n",
            "Epoch 480/1000\n",
            "40/40 - 1s - loss: 40.4763 - val_loss: 475.4221\n",
            "Epoch 481/1000\n",
            "40/40 - 1s - loss: 38.1810 - val_loss: 471.6086\n",
            "Epoch 482/1000\n",
            "40/40 - 1s - loss: 37.4751 - val_loss: 481.2781\n",
            "Epoch 483/1000\n",
            "40/40 - 1s - loss: 37.4534 - val_loss: 469.5334\n",
            "Epoch 484/1000\n",
            "40/40 - 1s - loss: 34.8262 - val_loss: 468.3692\n",
            "Epoch 485/1000\n",
            "40/40 - 1s - loss: 40.1460 - val_loss: 477.9950\n",
            "Epoch 486/1000\n",
            "40/40 - 1s - loss: 41.2954 - val_loss: 470.3421\n",
            "Epoch 487/1000\n",
            "40/40 - 1s - loss: 39.4261 - val_loss: 476.4592\n",
            "Epoch 488/1000\n",
            "40/40 - 1s - loss: 36.1768 - val_loss: 472.0656\n",
            "Epoch 489/1000\n",
            "40/40 - 1s - loss: 36.1216 - val_loss: 477.9666\n",
            "Epoch 490/1000\n",
            "40/40 - 1s - loss: 41.8626 - val_loss: 472.1089\n",
            "Epoch 491/1000\n",
            "40/40 - 1s - loss: 39.6519 - val_loss: 475.7694\n",
            "Epoch 492/1000\n",
            "40/40 - 1s - loss: 41.0345 - val_loss: 470.5848\n",
            "Epoch 493/1000\n",
            "40/40 - 1s - loss: 37.0183 - val_loss: 481.6572\n",
            "Epoch 494/1000\n",
            "40/40 - 1s - loss: 39.7623 - val_loss: 481.4586\n",
            "Epoch 495/1000\n",
            "40/40 - 1s - loss: 37.0401 - val_loss: 473.6427\n",
            "Epoch 496/1000\n",
            "40/40 - 1s - loss: 38.2835 - val_loss: 467.7555\n",
            "Epoch 497/1000\n",
            "40/40 - 1s - loss: 39.3105 - val_loss: 480.3172\n",
            "Epoch 498/1000\n",
            "40/40 - 1s - loss: 38.3211 - val_loss: 471.9612\n",
            "Epoch 499/1000\n",
            "40/40 - 1s - loss: 35.4757 - val_loss: 473.0100\n",
            "Epoch 500/1000\n",
            "40/40 - 1s - loss: 36.6978 - val_loss: 479.9675\n",
            "Epoch 501/1000\n",
            "40/40 - 1s - loss: 36.4810 - val_loss: 479.8023\n",
            "Epoch 502/1000\n",
            "40/40 - 1s - loss: 39.9429 - val_loss: 469.8899\n",
            "Epoch 503/1000\n",
            "40/40 - 1s - loss: 39.4341 - val_loss: 468.7724\n",
            "Epoch 504/1000\n",
            "40/40 - 1s - loss: 37.0208 - val_loss: 479.9625\n",
            "Epoch 505/1000\n",
            "40/40 - 1s - loss: 39.3889 - val_loss: 472.4910\n",
            "Epoch 506/1000\n",
            "40/40 - 1s - loss: 37.1007 - val_loss: 470.2046\n",
            "Epoch 507/1000\n",
            "40/40 - 1s - loss: 42.2942 - val_loss: 473.7132\n",
            "Epoch 508/1000\n",
            "40/40 - 1s - loss: 43.9094 - val_loss: 463.4549\n",
            "Epoch 509/1000\n",
            "40/40 - 1s - loss: 42.4635 - val_loss: 472.6501\n",
            "Epoch 510/1000\n",
            "40/40 - 1s - loss: 37.0309 - val_loss: 473.0817\n",
            "Epoch 511/1000\n",
            "40/40 - 1s - loss: 37.5350 - val_loss: 474.2493\n",
            "Epoch 512/1000\n",
            "40/40 - 1s - loss: 37.0491 - val_loss: 471.3943\n",
            "Epoch 513/1000\n",
            "40/40 - 1s - loss: 37.1175 - val_loss: 479.2498\n",
            "Epoch 514/1000\n",
            "40/40 - 1s - loss: 37.1501 - val_loss: 478.8171\n",
            "Epoch 515/1000\n",
            "40/40 - 1s - loss: 35.8033 - val_loss: 478.8804\n",
            "Epoch 516/1000\n",
            "40/40 - 1s - loss: 35.0522 - val_loss: 477.3284\n",
            "Epoch 517/1000\n",
            "40/40 - 1s - loss: 37.6358 - val_loss: 480.8235\n",
            "Epoch 518/1000\n",
            "40/40 - 1s - loss: 37.8532 - val_loss: 472.7926\n",
            "Epoch 519/1000\n",
            "40/40 - 1s - loss: 36.5803 - val_loss: 474.5078\n",
            "Epoch 520/1000\n",
            "40/40 - 1s - loss: 37.2280 - val_loss: 474.4761\n",
            "Epoch 521/1000\n",
            "40/40 - 1s - loss: 35.1171 - val_loss: 469.9637\n",
            "Epoch 522/1000\n",
            "40/40 - 1s - loss: 33.6584 - val_loss: 474.8239\n",
            "Epoch 523/1000\n",
            "40/40 - 1s - loss: 35.7044 - val_loss: 472.4385\n",
            "Epoch 524/1000\n",
            "40/40 - 1s - loss: 35.2237 - val_loss: 470.7823\n",
            "Epoch 525/1000\n",
            "40/40 - 1s - loss: 36.8663 - val_loss: 471.9249\n",
            "Epoch 526/1000\n",
            "40/40 - 1s - loss: 36.8424 - val_loss: 474.9963\n",
            "Epoch 527/1000\n",
            "40/40 - 1s - loss: 36.3968 - val_loss: 469.7999\n",
            "Epoch 528/1000\n",
            "40/40 - 1s - loss: 38.7000 - val_loss: 468.5763\n",
            "Epoch 529/1000\n",
            "40/40 - 1s - loss: 38.6117 - val_loss: 481.6592\n",
            "Epoch 530/1000\n",
            "40/40 - 1s - loss: 41.2026 - val_loss: 466.8849\n",
            "Epoch 531/1000\n",
            "40/40 - 1s - loss: 38.8908 - val_loss: 467.9309\n",
            "Epoch 532/1000\n",
            "40/40 - 1s - loss: 40.5926 - val_loss: 467.5756\n",
            "Epoch 533/1000\n",
            "40/40 - 1s - loss: 46.6421 - val_loss: 479.6397\n",
            "Epoch 534/1000\n",
            "40/40 - 1s - loss: 41.1143 - val_loss: 472.2933\n",
            "Epoch 535/1000\n",
            "40/40 - 1s - loss: 36.9825 - val_loss: 472.1809\n",
            "Epoch 536/1000\n",
            "40/40 - 1s - loss: 34.5049 - val_loss: 469.3266\n",
            "Epoch 537/1000\n",
            "40/40 - 1s - loss: 35.6975 - val_loss: 474.0354\n",
            "Epoch 538/1000\n",
            "40/40 - 1s - loss: 36.7694 - val_loss: 473.8438\n",
            "Epoch 539/1000\n",
            "40/40 - 1s - loss: 35.9749 - val_loss: 472.9764\n",
            "Epoch 540/1000\n",
            "40/40 - 1s - loss: 33.8944 - val_loss: 476.6916\n",
            "Epoch 541/1000\n",
            "40/40 - 1s - loss: 33.0599 - val_loss: 473.3624\n",
            "Epoch 542/1000\n",
            "40/40 - 1s - loss: 33.1726 - val_loss: 469.2147\n",
            "Epoch 543/1000\n",
            "40/40 - 1s - loss: 34.8642 - val_loss: 472.8307\n",
            "Epoch 544/1000\n",
            "40/40 - 1s - loss: 35.2724 - val_loss: 476.2134\n",
            "Epoch 545/1000\n",
            "40/40 - 1s - loss: 37.4628 - val_loss: 459.4369\n",
            "Epoch 546/1000\n",
            "40/40 - 1s - loss: 36.7361 - val_loss: 475.0582\n",
            "Epoch 547/1000\n",
            "40/40 - 1s - loss: 34.0110 - val_loss: 475.9703\n",
            "Epoch 548/1000\n",
            "40/40 - 1s - loss: 38.3446 - val_loss: 480.5632\n",
            "Epoch 549/1000\n",
            "40/40 - 1s - loss: 38.0171 - val_loss: 470.0373\n",
            "Epoch 550/1000\n",
            "40/40 - 1s - loss: 39.2934 - val_loss: 473.5307\n",
            "Epoch 551/1000\n",
            "40/40 - 1s - loss: 34.2391 - val_loss: 472.9827\n",
            "Epoch 552/1000\n",
            "40/40 - 1s - loss: 34.2529 - val_loss: 477.8563\n",
            "Epoch 553/1000\n",
            "40/40 - 1s - loss: 36.9193 - val_loss: 469.8906\n",
            "Epoch 554/1000\n",
            "40/40 - 1s - loss: 34.9279 - val_loss: 475.6374\n",
            "Epoch 555/1000\n",
            "40/40 - 1s - loss: 32.3184 - val_loss: 466.4399\n",
            "Epoch 556/1000\n",
            "40/40 - 1s - loss: 35.8262 - val_loss: 472.3921\n",
            "Epoch 557/1000\n",
            "40/40 - 1s - loss: 33.6604 - val_loss: 473.3825\n",
            "Epoch 558/1000\n",
            "40/40 - 1s - loss: 33.2987 - val_loss: 479.5812\n",
            "Epoch 559/1000\n",
            "40/40 - 1s - loss: 34.2503 - val_loss: 476.9210\n",
            "Epoch 560/1000\n",
            "40/40 - 1s - loss: 36.3549 - val_loss: 465.7023\n",
            "Epoch 561/1000\n",
            "40/40 - 1s - loss: 33.3995 - val_loss: 475.3086\n",
            "Epoch 562/1000\n",
            "40/40 - 1s - loss: 34.2780 - val_loss: 473.4093\n",
            "Epoch 563/1000\n",
            "40/40 - 1s - loss: 35.5260 - val_loss: 471.0004\n",
            "Epoch 564/1000\n",
            "40/40 - 1s - loss: 38.6553 - val_loss: 467.1007\n",
            "Epoch 565/1000\n",
            "40/40 - 1s - loss: 34.5874 - val_loss: 469.7415\n",
            "Epoch 566/1000\n",
            "40/40 - 1s - loss: 35.0182 - val_loss: 473.6702\n",
            "Epoch 567/1000\n",
            "40/40 - 1s - loss: 32.0092 - val_loss: 478.6195\n",
            "Epoch 568/1000\n",
            "40/40 - 1s - loss: 35.5424 - val_loss: 471.0465\n",
            "Epoch 569/1000\n",
            "40/40 - 1s - loss: 39.6280 - val_loss: 470.5446\n",
            "Epoch 570/1000\n",
            "40/40 - 1s - loss: 36.7830 - val_loss: 471.2884\n",
            "Epoch 571/1000\n",
            "40/40 - 1s - loss: 36.6131 - val_loss: 468.1037\n",
            "Epoch 572/1000\n",
            "40/40 - 1s - loss: 36.9314 - val_loss: 473.1808\n",
            "Epoch 573/1000\n",
            "40/40 - 1s - loss: 35.6305 - val_loss: 475.8290\n",
            "Epoch 574/1000\n",
            "40/40 - 1s - loss: 33.8848 - val_loss: 478.3514\n",
            "Epoch 575/1000\n",
            "40/40 - 1s - loss: 37.2258 - val_loss: 467.0427\n",
            "Epoch 576/1000\n",
            "40/40 - 1s - loss: 35.7527 - val_loss: 475.3310\n",
            "Epoch 577/1000\n",
            "40/40 - 1s - loss: 34.1753 - val_loss: 475.6181\n",
            "Epoch 578/1000\n",
            "40/40 - 1s - loss: 32.5860 - val_loss: 469.6851\n",
            "Epoch 579/1000\n",
            "40/40 - 1s - loss: 34.6831 - val_loss: 466.5557\n",
            "Epoch 580/1000\n",
            "40/40 - 1s - loss: 34.6701 - val_loss: 473.0304\n",
            "Epoch 581/1000\n",
            "40/40 - 1s - loss: 32.8568 - val_loss: 468.0977\n",
            "Epoch 582/1000\n",
            "40/40 - 1s - loss: 37.2289 - val_loss: 469.1970\n",
            "Epoch 583/1000\n",
            "40/40 - 1s - loss: 39.7665 - val_loss: 471.9006\n",
            "Epoch 584/1000\n",
            "40/40 - 1s - loss: 34.2096 - val_loss: 470.5148\n",
            "Epoch 585/1000\n",
            "40/40 - 1s - loss: 36.5486 - val_loss: 462.9399\n",
            "Epoch 586/1000\n",
            "40/40 - 1s - loss: 37.7972 - val_loss: 476.0255\n",
            "Epoch 587/1000\n",
            "40/40 - 1s - loss: 39.1148 - val_loss: 476.2807\n",
            "Epoch 588/1000\n",
            "40/40 - 1s - loss: 37.7487 - val_loss: 474.1675\n",
            "Epoch 589/1000\n",
            "40/40 - 1s - loss: 36.0128 - val_loss: 482.3128\n",
            "Epoch 590/1000\n",
            "40/40 - 1s - loss: 35.8289 - val_loss: 475.8098\n",
            "Epoch 591/1000\n",
            "40/40 - 1s - loss: 36.2918 - val_loss: 477.0602\n",
            "Epoch 592/1000\n",
            "40/40 - 1s - loss: 34.9592 - val_loss: 484.5915\n",
            "Epoch 593/1000\n",
            "40/40 - 1s - loss: 42.4908 - val_loss: 476.2812\n",
            "Epoch 594/1000\n",
            "40/40 - 1s - loss: 38.3421 - val_loss: 474.1934\n",
            "Epoch 595/1000\n",
            "40/40 - 1s - loss: 39.7005 - val_loss: 474.6270\n",
            "Epoch 596/1000\n",
            "40/40 - 1s - loss: 39.2193 - val_loss: 471.8824\n",
            "Epoch 597/1000\n",
            "40/40 - 1s - loss: 36.4592 - val_loss: 485.2543\n",
            "Epoch 598/1000\n",
            "40/40 - 1s - loss: 37.4641 - val_loss: 483.9299\n",
            "Epoch 599/1000\n",
            "40/40 - 1s - loss: 41.1684 - val_loss: 476.0119\n",
            "Epoch 600/1000\n",
            "40/40 - 1s - loss: 32.7138 - val_loss: 475.0429\n",
            "Epoch 601/1000\n",
            "40/40 - 1s - loss: 42.8900 - val_loss: 467.4417\n",
            "Epoch 602/1000\n",
            "40/40 - 1s - loss: 34.9062 - val_loss: 466.9981\n",
            "Epoch 603/1000\n",
            "40/40 - 1s - loss: 35.3693 - val_loss: 475.4207\n",
            "Epoch 604/1000\n",
            "40/40 - 1s - loss: 32.6197 - val_loss: 473.6951\n",
            "Epoch 605/1000\n",
            "40/40 - 1s - loss: 32.8124 - val_loss: 473.6045\n",
            "Epoch 606/1000\n",
            "40/40 - 1s - loss: 34.0213 - val_loss: 477.6064\n",
            "Epoch 607/1000\n",
            "40/40 - 1s - loss: 34.9400 - val_loss: 475.3570\n",
            "Epoch 608/1000\n",
            "40/40 - 1s - loss: 33.7561 - val_loss: 478.0568\n",
            "Epoch 609/1000\n",
            "40/40 - 1s - loss: 31.6885 - val_loss: 474.2467\n",
            "Epoch 610/1000\n",
            "40/40 - 1s - loss: 33.3580 - val_loss: 478.8062\n",
            "Epoch 611/1000\n",
            "40/40 - 1s - loss: 33.6437 - val_loss: 481.3114\n",
            "Epoch 612/1000\n",
            "40/40 - 1s - loss: 32.1803 - val_loss: 470.7987\n",
            "Epoch 613/1000\n",
            "40/40 - 1s - loss: 32.3531 - val_loss: 480.5924\n",
            "Epoch 614/1000\n",
            "40/40 - 1s - loss: 31.1097 - val_loss: 472.3323\n",
            "Epoch 615/1000\n",
            "40/40 - 1s - loss: 34.4875 - val_loss: 471.8794\n",
            "Epoch 616/1000\n",
            "40/40 - 1s - loss: 35.8773 - val_loss: 473.5508\n",
            "Epoch 617/1000\n",
            "40/40 - 1s - loss: 32.3481 - val_loss: 480.9598\n",
            "Epoch 618/1000\n",
            "40/40 - 1s - loss: 32.9146 - val_loss: 479.7671\n",
            "Epoch 619/1000\n",
            "40/40 - 1s - loss: 34.8610 - val_loss: 473.1901\n",
            "Epoch 620/1000\n",
            "40/40 - 1s - loss: 30.8322 - val_loss: 481.5635\n",
            "Epoch 621/1000\n",
            "40/40 - 1s - loss: 33.2017 - val_loss: 476.1331\n",
            "Epoch 622/1000\n",
            "40/40 - 1s - loss: 33.0200 - val_loss: 472.6987\n",
            "Epoch 623/1000\n",
            "40/40 - 1s - loss: 32.0113 - val_loss: 473.8004\n",
            "Epoch 624/1000\n",
            "40/40 - 1s - loss: 33.5098 - val_loss: 474.3643\n",
            "Epoch 625/1000\n",
            "40/40 - 1s - loss: 28.3009 - val_loss: 481.0846\n",
            "Epoch 626/1000\n",
            "40/40 - 1s - loss: 30.0533 - val_loss: 474.8701\n",
            "Epoch 627/1000\n",
            "40/40 - 1s - loss: 32.2095 - val_loss: 477.3716\n",
            "Epoch 628/1000\n",
            "40/40 - 1s - loss: 30.2359 - val_loss: 471.7065\n",
            "Epoch 629/1000\n",
            "40/40 - 1s - loss: 30.6774 - val_loss: 473.4796\n",
            "Epoch 630/1000\n",
            "40/40 - 1s - loss: 27.1054 - val_loss: 480.0114\n",
            "Epoch 631/1000\n",
            "40/40 - 1s - loss: 30.2268 - val_loss: 472.8290\n",
            "Epoch 632/1000\n",
            "40/40 - 1s - loss: 30.8871 - val_loss: 475.0826\n",
            "Epoch 633/1000\n",
            "40/40 - 1s - loss: 31.5436 - val_loss: 477.5584\n",
            "Epoch 634/1000\n",
            "40/40 - 1s - loss: 34.0338 - val_loss: 479.4377\n",
            "Epoch 635/1000\n",
            "40/40 - 1s - loss: 32.7924 - val_loss: 473.3595\n",
            "Epoch 636/1000\n",
            "40/40 - 1s - loss: 32.2593 - val_loss: 473.6199\n",
            "Epoch 637/1000\n",
            "40/40 - 1s - loss: 33.0916 - val_loss: 470.8764\n",
            "Epoch 638/1000\n",
            "40/40 - 1s - loss: 31.8429 - val_loss: 481.1191\n",
            "Epoch 639/1000\n",
            "40/40 - 1s - loss: 30.7854 - val_loss: 468.6476\n",
            "Epoch 640/1000\n",
            "40/40 - 1s - loss: 31.8093 - val_loss: 469.2471\n",
            "Epoch 641/1000\n",
            "40/40 - 1s - loss: 32.2103 - val_loss: 468.7872\n",
            "Epoch 642/1000\n",
            "40/40 - 1s - loss: 32.1175 - val_loss: 468.3004\n",
            "Epoch 643/1000\n",
            "40/40 - 1s - loss: 35.3746 - val_loss: 468.6899\n",
            "Epoch 644/1000\n",
            "40/40 - 1s - loss: 34.6353 - val_loss: 470.6358\n",
            "Epoch 645/1000\n",
            "40/40 - 1s - loss: 32.1131 - val_loss: 468.7453\n",
            "Epoch 646/1000\n",
            "40/40 - 1s - loss: 31.9817 - val_loss: 477.8350\n",
            "Epoch 647/1000\n",
            "40/40 - 1s - loss: 33.2965 - val_loss: 473.3035\n",
            "Epoch 648/1000\n",
            "40/40 - 1s - loss: 31.4058 - val_loss: 476.2105\n",
            "Epoch 649/1000\n",
            "40/40 - 1s - loss: 29.5178 - val_loss: 477.1378\n",
            "Epoch 650/1000\n",
            "40/40 - 1s - loss: 29.7885 - val_loss: 468.8540\n",
            "Epoch 651/1000\n",
            "40/40 - 1s - loss: 30.7218 - val_loss: 476.5897\n",
            "Epoch 652/1000\n",
            "40/40 - 1s - loss: 31.2175 - val_loss: 474.1581\n",
            "Epoch 653/1000\n",
            "40/40 - 1s - loss: 30.9460 - val_loss: 473.5392\n",
            "Epoch 654/1000\n",
            "40/40 - 1s - loss: 31.1884 - val_loss: 475.7519\n",
            "Epoch 655/1000\n",
            "40/40 - 1s - loss: 33.0012 - val_loss: 467.6591\n",
            "Epoch 656/1000\n",
            "40/40 - 1s - loss: 33.5433 - val_loss: 474.5182\n",
            "Epoch 657/1000\n",
            "40/40 - 1s - loss: 32.2419 - val_loss: 480.0266\n",
            "Epoch 658/1000\n",
            "40/40 - 1s - loss: 33.1727 - val_loss: 475.6848\n",
            "Epoch 659/1000\n",
            "40/40 - 1s - loss: 31.0104 - val_loss: 477.9214\n",
            "Epoch 660/1000\n",
            "40/40 - 1s - loss: 33.3569 - val_loss: 470.7718\n",
            "Epoch 661/1000\n",
            "40/40 - 1s - loss: 31.0531 - val_loss: 470.2405\n",
            "Epoch 662/1000\n",
            "40/40 - 1s - loss: 33.4383 - val_loss: 481.9295\n",
            "Epoch 663/1000\n",
            "40/40 - 1s - loss: 29.3381 - val_loss: 473.8821\n",
            "Epoch 664/1000\n",
            "40/40 - 1s - loss: 34.8332 - val_loss: 484.0473\n",
            "Epoch 665/1000\n",
            "40/40 - 1s - loss: 32.9627 - val_loss: 481.7317\n",
            "Epoch 666/1000\n",
            "40/40 - 1s - loss: 34.6963 - val_loss: 472.5464\n",
            "Epoch 667/1000\n",
            "40/40 - 1s - loss: 32.2316 - val_loss: 479.3252\n",
            "Epoch 668/1000\n",
            "40/40 - 1s - loss: 30.2194 - val_loss: 478.3240\n",
            "Epoch 669/1000\n",
            "40/40 - 1s - loss: 29.5321 - val_loss: 475.4377\n",
            "Epoch 670/1000\n",
            "40/40 - 1s - loss: 33.5921 - val_loss: 470.2328\n",
            "Epoch 671/1000\n",
            "40/40 - 1s - loss: 31.5022 - val_loss: 473.4573\n",
            "Epoch 672/1000\n",
            "40/40 - 1s - loss: 35.5463 - val_loss: 483.9406\n",
            "Epoch 673/1000\n",
            "40/40 - 1s - loss: 35.8746 - val_loss: 469.4429\n",
            "Epoch 674/1000\n",
            "40/40 - 1s - loss: 28.2888 - val_loss: 478.1012\n",
            "Epoch 675/1000\n",
            "40/40 - 1s - loss: 26.9964 - val_loss: 482.3381\n",
            "Epoch 676/1000\n",
            "40/40 - 1s - loss: 28.8465 - val_loss: 475.4178\n",
            "Epoch 677/1000\n",
            "40/40 - 1s - loss: 27.5710 - val_loss: 474.3948\n",
            "Epoch 678/1000\n",
            "40/40 - 1s - loss: 27.8935 - val_loss: 479.3554\n",
            "Epoch 679/1000\n",
            "40/40 - 1s - loss: 28.7021 - val_loss: 479.5806\n",
            "Epoch 680/1000\n",
            "40/40 - 1s - loss: 32.6299 - val_loss: 485.3333\n",
            "Epoch 681/1000\n",
            "40/40 - 1s - loss: 34.9822 - val_loss: 479.8279\n",
            "Epoch 682/1000\n",
            "40/40 - 1s - loss: 32.0287 - val_loss: 474.5519\n",
            "Epoch 683/1000\n",
            "40/40 - 1s - loss: 30.7477 - val_loss: 477.0489\n",
            "Epoch 684/1000\n",
            "40/40 - 1s - loss: 28.1670 - val_loss: 474.3167\n",
            "Epoch 685/1000\n",
            "40/40 - 1s - loss: 31.8094 - val_loss: 468.9391\n",
            "Epoch 686/1000\n",
            "40/40 - 1s - loss: 31.0966 - val_loss: 476.3767\n",
            "Epoch 687/1000\n",
            "40/40 - 1s - loss: 32.0934 - val_loss: 479.0984\n",
            "Epoch 688/1000\n",
            "40/40 - 1s - loss: 31.9886 - val_loss: 470.6757\n",
            "Epoch 689/1000\n",
            "40/40 - 1s - loss: 30.2725 - val_loss: 478.6593\n",
            "Epoch 690/1000\n",
            "40/40 - 1s - loss: 31.8234 - val_loss: 471.0459\n",
            "Epoch 691/1000\n",
            "40/40 - 1s - loss: 30.9077 - val_loss: 469.6519\n",
            "Epoch 692/1000\n",
            "40/40 - 1s - loss: 30.0566 - val_loss: 482.3192\n",
            "Epoch 693/1000\n",
            "40/40 - 1s - loss: 32.1709 - val_loss: 476.3246\n",
            "Epoch 694/1000\n",
            "40/40 - 1s - loss: 32.5881 - val_loss: 482.7334\n",
            "Epoch 695/1000\n",
            "40/40 - 1s - loss: 32.2310 - val_loss: 470.8907\n",
            "Epoch 696/1000\n",
            "40/40 - 1s - loss: 32.5288 - val_loss: 471.2889\n",
            "Epoch 697/1000\n",
            "40/40 - 1s - loss: 30.2748 - val_loss: 470.9688\n",
            "Epoch 698/1000\n",
            "40/40 - 1s - loss: 29.9900 - val_loss: 484.2881\n",
            "Epoch 699/1000\n",
            "40/40 - 1s - loss: 29.9446 - val_loss: 481.3787\n",
            "Epoch 700/1000\n",
            "40/40 - 1s - loss: 29.5644 - val_loss: 480.7829\n",
            "Epoch 701/1000\n",
            "40/40 - 1s - loss: 26.8030 - val_loss: 466.7080\n",
            "Epoch 702/1000\n",
            "40/40 - 1s - loss: 28.4507 - val_loss: 480.4453\n",
            "Epoch 703/1000\n",
            "40/40 - 1s - loss: 28.0986 - val_loss: 473.4070\n",
            "Epoch 704/1000\n",
            "40/40 - 1s - loss: 28.2178 - val_loss: 473.9375\n",
            "Epoch 705/1000\n",
            "40/40 - 1s - loss: 35.6254 - val_loss: 473.4670\n",
            "Epoch 706/1000\n",
            "40/40 - 1s - loss: 31.5934 - val_loss: 481.6814\n",
            "Epoch 707/1000\n",
            "40/40 - 1s - loss: 32.9338 - val_loss: 464.9384\n",
            "Epoch 708/1000\n",
            "40/40 - 1s - loss: 33.6433 - val_loss: 478.6678\n",
            "Epoch 709/1000\n",
            "40/40 - 1s - loss: 30.7502 - val_loss: 474.1973\n",
            "Epoch 710/1000\n",
            "40/40 - 1s - loss: 31.1921 - val_loss: 481.5219\n",
            "Epoch 711/1000\n",
            "40/40 - 1s - loss: 32.2463 - val_loss: 468.9484\n",
            "Epoch 712/1000\n",
            "40/40 - 1s - loss: 28.7465 - val_loss: 479.5526\n",
            "Epoch 713/1000\n",
            "40/40 - 1s - loss: 28.0291 - val_loss: 470.9397\n",
            "Epoch 714/1000\n",
            "40/40 - 1s - loss: 29.1762 - val_loss: 473.8511\n",
            "Epoch 715/1000\n",
            "40/40 - 1s - loss: 30.4449 - val_loss: 474.7505\n",
            "Epoch 716/1000\n",
            "40/40 - 1s - loss: 26.9008 - val_loss: 479.2700\n",
            "Epoch 717/1000\n",
            "40/40 - 1s - loss: 28.8226 - val_loss: 477.2725\n",
            "Epoch 718/1000\n",
            "40/40 - 1s - loss: 28.4968 - val_loss: 480.6512\n",
            "Epoch 719/1000\n",
            "40/40 - 1s - loss: 30.3537 - val_loss: 475.9144\n",
            "Epoch 720/1000\n",
            "40/40 - 1s - loss: 25.7666 - val_loss: 469.2051\n",
            "Epoch 721/1000\n",
            "40/40 - 1s - loss: 25.5040 - val_loss: 470.4458\n",
            "Epoch 722/1000\n",
            "40/40 - 1s - loss: 23.6763 - val_loss: 474.0635\n",
            "Epoch 723/1000\n",
            "40/40 - 1s - loss: 27.3998 - val_loss: 474.5282\n",
            "Epoch 724/1000\n",
            "40/40 - 1s - loss: 27.9647 - val_loss: 488.7923\n",
            "Epoch 725/1000\n",
            "40/40 - 1s - loss: 28.9585 - val_loss: 478.9775\n",
            "Epoch 726/1000\n",
            "40/40 - 1s - loss: 31.1906 - val_loss: 479.4439\n",
            "Epoch 727/1000\n",
            "40/40 - 1s - loss: 29.4974 - val_loss: 482.1306\n",
            "Epoch 728/1000\n",
            "40/40 - 1s - loss: 34.6146 - val_loss: 478.5128\n",
            "Epoch 729/1000\n",
            "40/40 - 1s - loss: 32.3854 - val_loss: 469.4458\n",
            "Epoch 730/1000\n",
            "40/40 - 1s - loss: 32.8332 - val_loss: 473.8956\n",
            "Epoch 731/1000\n",
            "40/40 - 1s - loss: 27.1319 - val_loss: 464.0859\n",
            "Epoch 732/1000\n",
            "40/40 - 1s - loss: 25.2896 - val_loss: 474.4087\n",
            "Epoch 733/1000\n",
            "40/40 - 1s - loss: 25.1476 - val_loss: 467.7617\n",
            "Epoch 734/1000\n",
            "40/40 - 1s - loss: 31.5166 - val_loss: 474.5237\n",
            "Epoch 735/1000\n",
            "40/40 - 1s - loss: 26.7559 - val_loss: 477.5483\n",
            "Epoch 736/1000\n",
            "40/40 - 1s - loss: 26.4143 - val_loss: 486.0962\n",
            "Epoch 737/1000\n",
            "40/40 - 1s - loss: 25.6008 - val_loss: 483.1997\n",
            "Epoch 738/1000\n",
            "40/40 - 1s - loss: 27.4676 - val_loss: 479.2829\n",
            "Epoch 739/1000\n",
            "40/40 - 1s - loss: 28.3589 - val_loss: 475.4005\n",
            "Epoch 740/1000\n",
            "40/40 - 1s - loss: 25.2509 - val_loss: 483.6399\n",
            "Epoch 741/1000\n",
            "40/40 - 1s - loss: 28.7894 - val_loss: 473.1535\n",
            "Epoch 742/1000\n",
            "40/40 - 1s - loss: 28.7260 - val_loss: 480.1736\n",
            "Epoch 743/1000\n",
            "40/40 - 1s - loss: 28.2774 - val_loss: 478.2112\n",
            "Epoch 744/1000\n",
            "40/40 - 1s - loss: 27.7681 - val_loss: 481.8584\n",
            "Epoch 745/1000\n",
            "40/40 - 1s - loss: 26.6950 - val_loss: 479.4228\n",
            "Epoch 746/1000\n",
            "40/40 - 1s - loss: 30.3075 - val_loss: 471.8546\n",
            "Epoch 747/1000\n",
            "40/40 - 1s - loss: 25.2185 - val_loss: 473.3121\n",
            "Epoch 748/1000\n",
            "40/40 - 1s - loss: 26.9842 - val_loss: 471.8220\n",
            "Epoch 749/1000\n",
            "40/40 - 1s - loss: 30.2370 - val_loss: 477.4000\n",
            "Epoch 750/1000\n",
            "40/40 - 1s - loss: 32.7129 - val_loss: 471.3970\n",
            "Epoch 751/1000\n",
            "40/40 - 1s - loss: 27.1914 - val_loss: 476.9894\n",
            "Epoch 752/1000\n",
            "40/40 - 1s - loss: 29.0622 - val_loss: 490.3728\n",
            "Epoch 753/1000\n",
            "40/40 - 1s - loss: 28.5775 - val_loss: 464.9632\n",
            "Epoch 754/1000\n",
            "40/40 - 1s - loss: 27.6401 - val_loss: 485.8490\n",
            "Epoch 755/1000\n",
            "40/40 - 1s - loss: 27.2485 - val_loss: 472.4680\n",
            "Epoch 756/1000\n",
            "40/40 - 1s - loss: 25.9365 - val_loss: 477.5681\n",
            "Epoch 757/1000\n",
            "40/40 - 1s - loss: 24.9086 - val_loss: 479.5791\n",
            "Epoch 758/1000\n",
            "40/40 - 1s - loss: 27.0428 - val_loss: 469.4203\n",
            "Epoch 759/1000\n",
            "40/40 - 1s - loss: 28.1809 - val_loss: 471.4471\n",
            "Epoch 760/1000\n",
            "40/40 - 1s - loss: 25.1109 - val_loss: 473.8867\n",
            "Epoch 761/1000\n",
            "40/40 - 1s - loss: 28.6219 - val_loss: 479.5878\n",
            "Epoch 762/1000\n",
            "40/40 - 1s - loss: 28.8726 - val_loss: 470.4152\n",
            "Epoch 763/1000\n",
            "40/40 - 1s - loss: 31.2220 - val_loss: 472.3601\n",
            "Epoch 764/1000\n",
            "40/40 - 1s - loss: 27.6288 - val_loss: 487.9225\n",
            "Epoch 765/1000\n",
            "40/40 - 1s - loss: 25.8967 - val_loss: 470.3933\n",
            "Epoch 766/1000\n",
            "40/40 - 1s - loss: 25.5070 - val_loss: 474.1446\n",
            "Epoch 767/1000\n",
            "40/40 - 1s - loss: 25.1766 - val_loss: 475.7037\n",
            "Epoch 768/1000\n",
            "40/40 - 1s - loss: 23.7361 - val_loss: 474.4433\n",
            "Epoch 769/1000\n",
            "40/40 - 1s - loss: 26.1285 - val_loss: 469.6939\n",
            "Epoch 770/1000\n",
            "40/40 - 1s - loss: 23.0996 - val_loss: 479.8231\n",
            "Epoch 771/1000\n",
            "40/40 - 1s - loss: 25.7942 - val_loss: 473.2352\n",
            "Epoch 772/1000\n",
            "40/40 - 1s - loss: 23.5047 - val_loss: 475.4969\n",
            "Epoch 773/1000\n",
            "40/40 - 1s - loss: 24.8795 - val_loss: 471.3099\n",
            "Epoch 774/1000\n",
            "40/40 - 1s - loss: 24.7524 - val_loss: 483.0112\n",
            "Epoch 775/1000\n",
            "40/40 - 1s - loss: 26.7498 - val_loss: 476.8231\n",
            "Epoch 776/1000\n",
            "40/40 - 1s - loss: 23.5826 - val_loss: 479.1019\n",
            "Epoch 777/1000\n",
            "40/40 - 1s - loss: 23.2266 - val_loss: 478.3611\n",
            "Epoch 778/1000\n",
            "40/40 - 1s - loss: 26.2446 - val_loss: 482.6154\n",
            "Epoch 779/1000\n",
            "40/40 - 1s - loss: 27.5658 - val_loss: 477.2513\n",
            "Epoch 780/1000\n",
            "40/40 - 1s - loss: 27.7787 - val_loss: 483.9940\n",
            "Epoch 781/1000\n",
            "40/40 - 1s - loss: 26.6483 - val_loss: 472.1364\n",
            "Epoch 782/1000\n",
            "40/40 - 1s - loss: 25.4463 - val_loss: 479.6760\n",
            "Epoch 783/1000\n",
            "40/40 - 1s - loss: 22.0875 - val_loss: 477.3888\n",
            "Epoch 784/1000\n",
            "40/40 - 1s - loss: 26.3700 - val_loss: 471.9627\n",
            "Epoch 785/1000\n",
            "40/40 - 1s - loss: 26.1607 - val_loss: 477.4714\n",
            "Epoch 786/1000\n",
            "40/40 - 1s - loss: 26.5318 - val_loss: 482.6324\n",
            "Epoch 787/1000\n",
            "40/40 - 1s - loss: 23.3247 - val_loss: 475.9504\n",
            "Epoch 788/1000\n",
            "40/40 - 1s - loss: 23.1633 - val_loss: 477.5559\n",
            "Epoch 789/1000\n",
            "40/40 - 1s - loss: 23.0626 - val_loss: 472.2503\n",
            "Epoch 790/1000\n",
            "40/40 - 1s - loss: 27.0844 - val_loss: 472.5706\n",
            "Epoch 791/1000\n",
            "40/40 - 1s - loss: 28.9738 - val_loss: 477.3382\n",
            "Epoch 792/1000\n",
            "40/40 - 1s - loss: 28.8994 - val_loss: 475.7256\n",
            "Epoch 793/1000\n",
            "40/40 - 1s - loss: 26.0276 - val_loss: 479.7660\n",
            "Epoch 794/1000\n",
            "40/40 - 1s - loss: 27.3050 - val_loss: 481.7388\n",
            "Epoch 795/1000\n",
            "40/40 - 1s - loss: 27.7629 - val_loss: 493.2129\n",
            "Epoch 796/1000\n",
            "40/40 - 1s - loss: 26.8298 - val_loss: 483.7193\n",
            "Epoch 797/1000\n",
            "40/40 - 1s - loss: 26.4876 - val_loss: 486.5719\n",
            "Epoch 798/1000\n",
            "40/40 - 1s - loss: 23.2212 - val_loss: 479.1291\n",
            "Epoch 799/1000\n",
            "40/40 - 1s - loss: 23.8854 - val_loss: 490.2697\n",
            "Epoch 800/1000\n",
            "40/40 - 1s - loss: 25.2879 - val_loss: 487.9966\n",
            "Epoch 801/1000\n",
            "40/40 - 1s - loss: 23.5721 - val_loss: 481.5576\n",
            "Epoch 802/1000\n",
            "40/40 - 1s - loss: 27.7940 - val_loss: 469.2027\n",
            "Epoch 803/1000\n",
            "40/40 - 1s - loss: 25.4461 - val_loss: 483.0009\n",
            "Epoch 804/1000\n",
            "40/40 - 1s - loss: 24.3042 - val_loss: 480.8445\n",
            "Epoch 805/1000\n",
            "40/40 - 1s - loss: 23.9302 - val_loss: 479.4840\n",
            "Epoch 806/1000\n",
            "40/40 - 1s - loss: 26.9165 - val_loss: 473.3831\n",
            "Epoch 807/1000\n",
            "40/40 - 1s - loss: 25.2323 - val_loss: 475.4611\n",
            "Epoch 808/1000\n",
            "40/40 - 1s - loss: 23.2220 - val_loss: 474.8476\n",
            "Epoch 809/1000\n",
            "40/40 - 1s - loss: 22.2782 - val_loss: 482.5131\n",
            "Epoch 810/1000\n",
            "40/40 - 1s - loss: 21.9913 - val_loss: 484.9725\n",
            "Epoch 811/1000\n",
            "40/40 - 1s - loss: 24.4508 - val_loss: 478.2138\n",
            "Epoch 812/1000\n",
            "40/40 - 1s - loss: 26.4126 - val_loss: 477.3176\n",
            "Epoch 813/1000\n",
            "40/40 - 1s - loss: 26.6103 - val_loss: 480.9916\n",
            "Epoch 814/1000\n",
            "40/40 - 1s - loss: 26.0248 - val_loss: 469.6375\n",
            "Epoch 815/1000\n",
            "40/40 - 1s - loss: 24.3645 - val_loss: 472.8654\n",
            "Epoch 816/1000\n",
            "40/40 - 1s - loss: 24.9622 - val_loss: 473.3145\n",
            "Epoch 817/1000\n",
            "40/40 - 1s - loss: 26.4850 - val_loss: 483.9485\n",
            "Epoch 818/1000\n",
            "40/40 - 1s - loss: 23.8884 - val_loss: 476.9290\n",
            "Epoch 819/1000\n",
            "40/40 - 1s - loss: 24.1922 - val_loss: 475.7897\n",
            "Epoch 820/1000\n",
            "40/40 - 1s - loss: 23.4180 - val_loss: 477.8032\n",
            "Epoch 821/1000\n",
            "40/40 - 1s - loss: 22.2735 - val_loss: 477.2446\n",
            "Epoch 822/1000\n",
            "40/40 - 1s - loss: 24.1492 - val_loss: 484.2921\n",
            "Epoch 823/1000\n",
            "40/40 - 1s - loss: 25.4143 - val_loss: 477.2927\n",
            "Epoch 824/1000\n",
            "40/40 - 1s - loss: 24.2334 - val_loss: 483.7480\n",
            "Epoch 825/1000\n",
            "40/40 - 1s - loss: 24.6214 - val_loss: 484.9549\n",
            "Epoch 826/1000\n",
            "40/40 - 1s - loss: 24.9059 - val_loss: 479.7256\n",
            "Epoch 827/1000\n",
            "40/40 - 1s - loss: 25.5241 - val_loss: 484.5144\n",
            "Epoch 828/1000\n",
            "40/40 - 1s - loss: 25.9243 - val_loss: 479.3523\n",
            "Epoch 829/1000\n",
            "40/40 - 1s - loss: 24.0487 - val_loss: 479.9478\n",
            "Epoch 830/1000\n",
            "40/40 - 1s - loss: 20.7346 - val_loss: 483.1924\n",
            "Epoch 831/1000\n",
            "40/40 - 1s - loss: 22.8372 - val_loss: 478.4686\n",
            "Epoch 832/1000\n",
            "40/40 - 1s - loss: 23.2579 - val_loss: 474.3278\n",
            "Epoch 833/1000\n",
            "40/40 - 1s - loss: 23.6444 - val_loss: 478.6716\n",
            "Epoch 834/1000\n",
            "40/40 - 1s - loss: 31.4352 - val_loss: 478.4626\n",
            "Epoch 835/1000\n",
            "40/40 - 1s - loss: 25.0501 - val_loss: 479.4158\n",
            "Epoch 836/1000\n",
            "40/40 - 1s - loss: 27.3555 - val_loss: 475.8725\n",
            "Epoch 837/1000\n",
            "40/40 - 1s - loss: 25.5705 - val_loss: 479.2221\n",
            "Epoch 838/1000\n",
            "40/40 - 1s - loss: 22.5178 - val_loss: 474.1609\n",
            "Epoch 839/1000\n",
            "40/40 - 1s - loss: 21.5485 - val_loss: 489.3687\n",
            "Epoch 840/1000\n",
            "40/40 - 1s - loss: 24.6323 - val_loss: 487.5088\n",
            "Epoch 841/1000\n",
            "40/40 - 1s - loss: 25.1063 - val_loss: 482.2039\n",
            "Epoch 842/1000\n",
            "40/40 - 1s - loss: 25.6138 - val_loss: 470.2928\n",
            "Epoch 843/1000\n",
            "40/40 - 1s - loss: 25.6272 - val_loss: 481.1436\n",
            "Epoch 844/1000\n",
            "40/40 - 1s - loss: 28.1151 - val_loss: 475.7472\n",
            "Epoch 845/1000\n",
            "40/40 - 1s - loss: 24.0487 - val_loss: 480.3550\n",
            "Epoch 846/1000\n",
            "40/40 - 1s - loss: 22.4432 - val_loss: 480.7557\n",
            "Epoch 847/1000\n",
            "40/40 - 1s - loss: 19.2127 - val_loss: 479.8989\n",
            "Epoch 848/1000\n",
            "40/40 - 1s - loss: 23.1356 - val_loss: 482.6728\n",
            "Epoch 849/1000\n",
            "40/40 - 1s - loss: 20.7269 - val_loss: 483.3140\n",
            "Epoch 850/1000\n",
            "40/40 - 1s - loss: 24.6612 - val_loss: 490.5342\n",
            "Epoch 851/1000\n",
            "40/40 - 1s - loss: 24.4772 - val_loss: 472.8997\n",
            "Epoch 852/1000\n",
            "40/40 - 1s - loss: 24.1740 - val_loss: 477.6443\n",
            "Epoch 853/1000\n",
            "40/40 - 1s - loss: 23.6636 - val_loss: 484.4318\n",
            "Epoch 854/1000\n",
            "40/40 - 1s - loss: 21.7098 - val_loss: 480.9953\n",
            "Epoch 855/1000\n",
            "40/40 - 1s - loss: 24.8007 - val_loss: 477.9756\n",
            "Epoch 856/1000\n",
            "40/40 - 1s - loss: 25.4149 - val_loss: 477.2970\n",
            "Epoch 857/1000\n",
            "40/40 - 1s - loss: 23.8705 - val_loss: 476.5885\n",
            "Epoch 858/1000\n",
            "40/40 - 1s - loss: 22.9886 - val_loss: 482.6523\n",
            "Epoch 859/1000\n",
            "40/40 - 1s - loss: 21.7341 - val_loss: 476.5975\n",
            "Epoch 860/1000\n",
            "40/40 - 1s - loss: 21.5503 - val_loss: 483.1755\n",
            "Epoch 861/1000\n",
            "40/40 - 1s - loss: 22.3859 - val_loss: 485.7654\n",
            "Epoch 862/1000\n",
            "40/40 - 1s - loss: 24.5085 - val_loss: 483.3931\n",
            "Epoch 863/1000\n",
            "40/40 - 1s - loss: 22.8894 - val_loss: 477.9686\n",
            "Epoch 864/1000\n",
            "40/40 - 1s - loss: 19.8610 - val_loss: 479.6046\n",
            "Epoch 865/1000\n",
            "40/40 - 1s - loss: 20.0540 - val_loss: 484.7569\n",
            "Epoch 866/1000\n",
            "40/40 - 1s - loss: 23.2738 - val_loss: 483.2900\n",
            "Epoch 867/1000\n",
            "40/40 - 1s - loss: 20.9137 - val_loss: 480.7826\n",
            "Epoch 868/1000\n",
            "40/40 - 1s - loss: 20.8207 - val_loss: 480.5554\n",
            "Epoch 869/1000\n",
            "40/40 - 1s - loss: 22.0682 - val_loss: 480.8097\n",
            "Epoch 870/1000\n",
            "40/40 - 1s - loss: 24.1681 - val_loss: 488.9654\n",
            "Epoch 871/1000\n",
            "40/40 - 1s - loss: 30.1914 - val_loss: 492.0530\n",
            "Epoch 872/1000\n",
            "40/40 - 1s - loss: 27.4236 - val_loss: 482.4149\n",
            "Epoch 873/1000\n",
            "40/40 - 1s - loss: 24.8229 - val_loss: 484.8764\n",
            "Epoch 874/1000\n",
            "40/40 - 1s - loss: 26.4920 - val_loss: 486.0893\n",
            "Epoch 875/1000\n",
            "40/40 - 1s - loss: 23.8192 - val_loss: 480.6702\n",
            "Epoch 876/1000\n",
            "40/40 - 1s - loss: 25.4370 - val_loss: 499.0506\n",
            "Epoch 877/1000\n",
            "40/40 - 1s - loss: 34.7266 - val_loss: 474.7216\n",
            "Epoch 878/1000\n",
            "40/40 - 1s - loss: 27.7915 - val_loss: 476.5870\n",
            "Epoch 879/1000\n",
            "40/40 - 1s - loss: 34.3294 - val_loss: 481.6810\n",
            "Epoch 880/1000\n",
            "40/40 - 1s - loss: 26.0072 - val_loss: 472.2722\n",
            "Epoch 881/1000\n",
            "40/40 - 1s - loss: 20.5426 - val_loss: 473.7437\n",
            "Epoch 882/1000\n",
            "40/40 - 1s - loss: 23.0025 - val_loss: 472.8236\n",
            "Epoch 883/1000\n",
            "40/40 - 1s - loss: 22.0059 - val_loss: 471.7606\n",
            "Epoch 884/1000\n",
            "40/40 - 1s - loss: 22.7732 - val_loss: 475.4814\n",
            "Epoch 885/1000\n",
            "40/40 - 1s - loss: 22.3231 - val_loss: 475.7582\n",
            "Epoch 886/1000\n",
            "40/40 - 1s - loss: 21.6015 - val_loss: 484.2258\n",
            "Epoch 887/1000\n",
            "40/40 - 1s - loss: 25.9462 - val_loss: 476.2449\n",
            "Epoch 888/1000\n",
            "40/40 - 1s - loss: 22.5979 - val_loss: 474.3773\n",
            "Epoch 889/1000\n",
            "40/40 - 1s - loss: 20.0642 - val_loss: 476.3581\n",
            "Epoch 890/1000\n",
            "40/40 - 1s - loss: 21.1643 - val_loss: 479.3382\n",
            "Epoch 891/1000\n",
            "40/40 - 1s - loss: 20.4602 - val_loss: 478.4434\n",
            "Epoch 892/1000\n",
            "40/40 - 1s - loss: 20.6596 - val_loss: 477.6938\n",
            "Epoch 893/1000\n",
            "40/40 - 1s - loss: 22.1728 - val_loss: 465.6793\n",
            "Epoch 894/1000\n",
            "40/40 - 1s - loss: 23.9281 - val_loss: 480.4872\n",
            "Epoch 895/1000\n",
            "40/40 - 1s - loss: 18.1799 - val_loss: 475.7423\n",
            "Epoch 896/1000\n",
            "40/40 - 1s - loss: 20.3024 - val_loss: 478.5297\n",
            "Epoch 897/1000\n",
            "40/40 - 1s - loss: 20.2371 - val_loss: 477.2021\n",
            "Epoch 898/1000\n",
            "40/40 - 1s - loss: 19.9724 - val_loss: 472.5175\n",
            "Epoch 899/1000\n",
            "40/40 - 1s - loss: 21.4510 - val_loss: 477.8849\n",
            "Epoch 900/1000\n",
            "40/40 - 1s - loss: 20.4237 - val_loss: 477.0215\n",
            "Epoch 901/1000\n",
            "40/40 - 1s - loss: 21.0360 - val_loss: 475.9554\n",
            "Epoch 902/1000\n",
            "40/40 - 1s - loss: 23.0873 - val_loss: 482.2476\n",
            "Epoch 903/1000\n",
            "40/40 - 1s - loss: 23.1292 - val_loss: 485.1451\n",
            "Epoch 904/1000\n",
            "40/40 - 1s - loss: 26.0608 - val_loss: 471.0669\n",
            "Epoch 905/1000\n",
            "40/40 - 1s - loss: 26.9603 - val_loss: 480.5533\n",
            "Epoch 906/1000\n",
            "40/40 - 1s - loss: 23.8118 - val_loss: 475.2319\n",
            "Epoch 907/1000\n",
            "40/40 - 1s - loss: 23.8602 - val_loss: 470.8898\n",
            "Epoch 908/1000\n",
            "40/40 - 1s - loss: 25.1180 - val_loss: 475.2254\n",
            "Epoch 909/1000\n",
            "40/40 - 1s - loss: 24.5677 - val_loss: 475.1167\n",
            "Epoch 910/1000\n",
            "40/40 - 1s - loss: 19.8595 - val_loss: 476.4187\n",
            "Epoch 911/1000\n",
            "40/40 - 1s - loss: 21.5835 - val_loss: 482.5323\n",
            "Epoch 912/1000\n",
            "40/40 - 1s - loss: 22.7488 - val_loss: 474.9796\n",
            "Epoch 913/1000\n",
            "40/40 - 1s - loss: 22.9710 - val_loss: 484.6711\n",
            "Epoch 914/1000\n",
            "40/40 - 1s - loss: 33.1225 - val_loss: 485.3855\n",
            "Epoch 915/1000\n",
            "40/40 - 1s - loss: 31.9191 - val_loss: 474.2749\n",
            "Epoch 916/1000\n",
            "40/40 - 1s - loss: 25.9650 - val_loss: 466.0819\n",
            "Epoch 917/1000\n",
            "40/40 - 1s - loss: 24.7201 - val_loss: 474.3505\n",
            "Epoch 918/1000\n",
            "40/40 - 1s - loss: 25.8342 - val_loss: 479.7318\n",
            "Epoch 919/1000\n",
            "40/40 - 1s - loss: 23.8364 - val_loss: 478.4670\n",
            "Epoch 920/1000\n",
            "40/40 - 1s - loss: 22.0635 - val_loss: 474.2867\n",
            "Epoch 921/1000\n",
            "40/40 - 1s - loss: 20.3544 - val_loss: 476.2725\n",
            "Epoch 922/1000\n",
            "40/40 - 1s - loss: 21.1656 - val_loss: 471.8562\n",
            "Epoch 923/1000\n",
            "40/40 - 1s - loss: 23.8876 - val_loss: 478.5167\n",
            "Epoch 924/1000\n",
            "40/40 - 1s - loss: 24.4952 - val_loss: 476.2923\n",
            "Epoch 925/1000\n",
            "40/40 - 1s - loss: 23.5934 - val_loss: 476.0464\n",
            "Epoch 926/1000\n",
            "40/40 - 1s - loss: 21.4662 - val_loss: 469.7809\n",
            "Epoch 927/1000\n",
            "40/40 - 1s - loss: 24.4816 - val_loss: 477.5168\n",
            "Epoch 928/1000\n",
            "40/40 - 1s - loss: 23.8461 - val_loss: 477.1454\n",
            "Epoch 929/1000\n",
            "40/40 - 1s - loss: 23.5619 - val_loss: 483.0402\n",
            "Epoch 930/1000\n",
            "40/40 - 1s - loss: 27.7893 - val_loss: 473.5928\n",
            "Epoch 931/1000\n",
            "40/40 - 1s - loss: 26.9338 - val_loss: 481.2162\n",
            "Epoch 932/1000\n",
            "40/40 - 1s - loss: 22.6605 - val_loss: 484.0432\n",
            "Epoch 933/1000\n",
            "40/40 - 1s - loss: 22.1719 - val_loss: 486.0184\n",
            "Epoch 934/1000\n",
            "40/40 - 1s - loss: 21.5971 - val_loss: 479.5924\n",
            "Epoch 935/1000\n",
            "40/40 - 1s - loss: 21.5005 - val_loss: 478.3147\n",
            "Epoch 936/1000\n",
            "40/40 - 1s - loss: 22.2276 - val_loss: 476.3708\n",
            "Epoch 937/1000\n",
            "40/40 - 1s - loss: 23.1259 - val_loss: 472.4329\n",
            "Epoch 938/1000\n",
            "40/40 - 1s - loss: 22.3667 - val_loss: 475.1723\n",
            "Epoch 939/1000\n",
            "40/40 - 1s - loss: 25.0137 - val_loss: 475.8291\n",
            "Epoch 940/1000\n",
            "40/40 - 1s - loss: 23.0058 - val_loss: 470.3033\n",
            "Epoch 941/1000\n",
            "40/40 - 1s - loss: 19.4770 - val_loss: 478.5596\n",
            "Epoch 942/1000\n",
            "40/40 - 1s - loss: 19.5484 - val_loss: 482.7979\n",
            "Epoch 943/1000\n",
            "40/40 - 1s - loss: 24.7171 - val_loss: 470.9824\n",
            "Epoch 944/1000\n",
            "40/40 - 1s - loss: 20.3596 - val_loss: 479.8651\n",
            "Epoch 945/1000\n",
            "40/40 - 1s - loss: 18.3796 - val_loss: 476.5891\n",
            "Epoch 946/1000\n",
            "40/40 - 1s - loss: 20.2287 - val_loss: 479.7045\n",
            "Epoch 947/1000\n",
            "40/40 - 1s - loss: 20.0439 - val_loss: 474.0077\n",
            "Epoch 948/1000\n",
            "40/40 - 1s - loss: 21.0041 - val_loss: 470.8317\n",
            "Epoch 949/1000\n",
            "40/40 - 1s - loss: 19.8512 - val_loss: 476.6180\n",
            "Epoch 950/1000\n",
            "40/40 - 1s - loss: 19.3974 - val_loss: 474.1719\n",
            "Epoch 951/1000\n",
            "40/40 - 1s - loss: 18.5954 - val_loss: 475.5921\n",
            "Epoch 952/1000\n",
            "40/40 - 1s - loss: 19.7685 - val_loss: 471.9290\n",
            "Epoch 953/1000\n",
            "40/40 - 1s - loss: 19.9397 - val_loss: 471.1955\n",
            "Epoch 954/1000\n",
            "40/40 - 1s - loss: 22.1592 - val_loss: 483.2585\n",
            "Epoch 955/1000\n",
            "40/40 - 1s - loss: 23.3319 - val_loss: 482.6755\n",
            "Epoch 956/1000\n",
            "40/40 - 1s - loss: 22.5719 - val_loss: 482.6406\n",
            "Epoch 957/1000\n",
            "40/40 - 1s - loss: 24.1999 - val_loss: 480.8668\n",
            "Epoch 958/1000\n",
            "40/40 - 1s - loss: 23.1974 - val_loss: 477.6222\n",
            "Epoch 959/1000\n",
            "40/40 - 1s - loss: 20.5591 - val_loss: 473.9927\n",
            "Epoch 960/1000\n",
            "40/40 - 1s - loss: 20.7100 - val_loss: 477.8329\n",
            "Epoch 961/1000\n",
            "40/40 - 1s - loss: 21.8086 - val_loss: 475.4780\n",
            "Epoch 962/1000\n",
            "40/40 - 1s - loss: 20.2849 - val_loss: 475.2263\n",
            "Epoch 963/1000\n",
            "40/40 - 1s - loss: 20.9800 - val_loss: 473.0233\n",
            "Epoch 964/1000\n",
            "40/40 - 1s - loss: 24.4072 - val_loss: 475.8633\n",
            "Epoch 965/1000\n",
            "40/40 - 1s - loss: 22.4665 - val_loss: 478.2110\n",
            "Epoch 966/1000\n",
            "40/40 - 1s - loss: 21.3298 - val_loss: 473.8180\n",
            "Epoch 967/1000\n",
            "40/40 - 1s - loss: 36.6417 - val_loss: 475.4958\n",
            "Epoch 968/1000\n",
            "40/40 - 1s - loss: 27.1450 - val_loss: 476.5346\n",
            "Epoch 969/1000\n",
            "40/40 - 1s - loss: 27.5023 - val_loss: 473.5224\n",
            "Epoch 970/1000\n",
            "40/40 - 1s - loss: 25.3981 - val_loss: 474.3620\n",
            "Epoch 971/1000\n",
            "40/40 - 1s - loss: 23.5632 - val_loss: 484.7735\n",
            "Epoch 972/1000\n",
            "40/40 - 1s - loss: 23.9135 - val_loss: 473.1419\n",
            "Epoch 973/1000\n",
            "40/40 - 1s - loss: 22.6599 - val_loss: 474.5213\n",
            "Epoch 974/1000\n",
            "40/40 - 1s - loss: 24.6729 - val_loss: 476.3187\n",
            "Epoch 975/1000\n",
            "40/40 - 1s - loss: 22.5128 - val_loss: 473.8004\n",
            "Epoch 976/1000\n",
            "40/40 - 1s - loss: 20.7294 - val_loss: 473.3315\n",
            "Epoch 977/1000\n",
            "40/40 - 1s - loss: 20.0922 - val_loss: 474.1370\n",
            "Epoch 978/1000\n",
            "40/40 - 1s - loss: 21.3547 - val_loss: 471.7462\n",
            "Epoch 979/1000\n",
            "40/40 - 1s - loss: 22.1129 - val_loss: 478.8212\n",
            "Epoch 980/1000\n",
            "40/40 - 1s - loss: 20.6742 - val_loss: 481.9361\n",
            "Epoch 981/1000\n",
            "40/40 - 1s - loss: 22.1835 - val_loss: 476.8535\n",
            "Epoch 982/1000\n",
            "40/40 - 1s - loss: 21.6064 - val_loss: 482.0725\n",
            "Epoch 983/1000\n",
            "40/40 - 1s - loss: 21.4479 - val_loss: 480.0564\n",
            "Epoch 984/1000\n",
            "40/40 - 1s - loss: 21.5854 - val_loss: 473.0935\n",
            "Epoch 985/1000\n",
            "40/40 - 1s - loss: 20.7790 - val_loss: 481.1657\n",
            "Epoch 986/1000\n",
            "40/40 - 1s - loss: 24.9205 - val_loss: 478.4855\n",
            "Epoch 987/1000\n",
            "40/40 - 1s - loss: 22.4309 - val_loss: 472.4094\n",
            "Epoch 988/1000\n",
            "40/40 - 1s - loss: 20.4724 - val_loss: 475.6664\n",
            "Epoch 989/1000\n",
            "40/40 - 1s - loss: 20.5345 - val_loss: 481.1504\n",
            "Epoch 990/1000\n",
            "40/40 - 1s - loss: 20.3579 - val_loss: 478.5512\n",
            "Epoch 991/1000\n",
            "40/40 - 1s - loss: 20.7838 - val_loss: 476.5805\n",
            "Epoch 992/1000\n",
            "40/40 - 1s - loss: 21.2628 - val_loss: 476.1313\n",
            "Epoch 993/1000\n",
            "40/40 - 1s - loss: 19.3540 - val_loss: 480.4317\n",
            "Epoch 994/1000\n",
            "40/40 - 1s - loss: 21.9047 - val_loss: 476.6167\n",
            "Epoch 995/1000\n",
            "40/40 - 1s - loss: 21.3594 - val_loss: 481.3555\n",
            "Epoch 996/1000\n",
            "40/40 - 1s - loss: 19.8389 - val_loss: 481.8431\n",
            "Epoch 997/1000\n",
            "40/40 - 1s - loss: 18.3414 - val_loss: 477.0166\n",
            "Epoch 998/1000\n",
            "40/40 - 1s - loss: 19.7871 - val_loss: 485.3340\n",
            "Epoch 999/1000\n",
            "40/40 - 1s - loss: 20.0604 - val_loss: 481.4512\n",
            "Epoch 1000/1000\n",
            "40/40 - 1s - loss: 18.9257 - val_loss: 484.0271\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "aeBMJ1A1gj45",
        "outputId": "554761ea-0102-4be1-cec8-ce84ee7295d0"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize=(8,5))\r\n",
        "plt.plot(np.arange(epochs), history.history['loss'], 'o-',\r\n",
        "         label='Training loss')\r\n",
        "plt.plot(np.arange(epochs), history.history['val_loss'], 'o-',\r\n",
        "         label='Validation loss')\r\n",
        "plt.xlabel(\"epoch\", fontsize=16)\r\n",
        "plt.ylabel(\"MAE\", fontsize=16)\r\n",
        "plt.legend(bbox_to_anchor=(1.01,1), fontsize=12);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaxFERRQhatl"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}